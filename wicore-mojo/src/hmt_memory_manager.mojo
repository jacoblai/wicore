"""
HMT åˆ†å±‚å†…å­˜ç®¡ç†å™¨ - WiCore Mojo æ¨ç†å¼•æ“
å®ç°ä¸‰çº§å­˜å‚¨ç®¡ç†ï¼šGPUæ˜¾å­˜ â†’ CPUå†…å­˜ â†’ NVMeå­˜å‚¨
é›†æˆ AÂ²CR (Attention-Aware Cache Replacement) ç®—æ³•
æ”¯æŒå¼‚æ„ç¡¬ä»¶çš„ç»Ÿä¸€å†…å­˜æŠ½è±¡
"""

from memory import UnsafePointer
from max import engine  
from collections import Dict, List
from python import Python
from .device_manager import DeviceManager, DeviceInfo
import time
import math

alias BLOCK_SIZE = 4096  # 4KB å›ºå®šå—å¤§å°
alias GPU_TIER = 0       # GPU æ˜¾å­˜å±‚
alias CPU_TIER = 1       # CPU å†…å­˜å±‚  
alias NVME_TIER = 2      # NVMe å­˜å‚¨å±‚

struct MemoryBlock:
    """å†…å­˜å—ç»“æ„ä½“"""
    var ptr: UnsafePointer[UInt8]  # å†…å­˜æŒ‡é’ˆ
    var size: Int                   # å—å¤§å°
    var device_id: String           # æ‰€å±è®¾å¤‡
    var tier: Int                   # å­˜å‚¨å±‚çº§ (0=GPU, 1=CPU, 2=NVMe)
    var block_id: String            # å—æ ‡è¯†ç¬¦
    var access_count: Int           # è®¿é—®æ¬¡æ•°
    var last_access_time: Float64   # æœ€åè®¿é—®æ—¶é—´
    var attention_score: Float64    # æ³¨æ„åŠ›åˆ†æ•°
    var is_dirty: Bool              # æ˜¯å¦å·²ä¿®æ”¹
    var reference_count: Int        # å¼•ç”¨è®¡æ•°
    
    fn __init__(inout self):
        """é»˜è®¤åˆå§‹åŒ–"""
        self.ptr = UnsafePointer[UInt8]()
        self.size = 0
        self.device_id = ""
        self.tier = CPU_TIER
        self.block_id = ""
        self.access_count = 0
        self.last_access_time = 0.0
        self.attention_score = 0.0
        self.is_dirty = False
        self.reference_count = 0
    
    fn __init__(inout self, ptr: UnsafePointer[UInt8], size: Int, device_id: String, tier: Int):
        """è‡ªå®šä¹‰åˆå§‹åŒ–"""
        self.ptr = ptr
        self.size = size
        self.device_id = device_id
        self.tier = tier
        self.block_id = self._generate_block_id()
        self.access_count = 0
        self.last_access_time = time.time_ns() / 1e9
        self.attention_score = 0.0
        self.is_dirty = False
        self.reference_count = 1
    
    fn update_access(inout self, attention_score: Float64 = 0.0):
        """æ›´æ–°è®¿é—®ä¿¡æ¯"""
        self.access_count += 1
        self.last_access_time = time.time_ns() / 1e9
        if attention_score > 0.0:
            self.attention_score = attention_score
    
    fn calculate_cache_score(self, params: A2CRParams) -> Float64:
        """è®¡ç®— AÂ²CR ç¼“å­˜åˆ†æ•°"""
        current_time = time.time_ns() / 1e9
        time_decay = math.exp(-params.time_decay_factor * (current_time - self.last_access_time))
        
        # ç»¼åˆè¯„åˆ†ï¼šæ³¨æ„åŠ›æƒé‡ + é¢‘ç‡æƒé‡ + æ—¶é—´è¡°å‡æƒé‡
        score = (params.attention_weight * self.attention_score + 
                params.frequency_weight * math.log(1.0 + Float64(self.access_count)) +
                params.recency_weight * time_decay)
        
        return score
    
    fn _generate_block_id(self) -> String:
        """ç”Ÿæˆå—ID"""
        return self.device_id + "_" + str(self.size) + "_" + str(time.time_ns())


struct A2CRParams:
    """AÂ²CR ç®—æ³•å‚æ•°"""
    var time_decay_factor: Float64    # æ—¶é—´è¡°å‡å› å­
    var attention_weight: Float64     # æ³¨æ„åŠ›æƒé‡
    var frequency_weight: Float64     # é¢‘ç‡æƒé‡
    var recency_weight: Float64       # æ—¶æ•ˆæƒé‡
    var eviction_threshold: Float64   # é©±é€é˜ˆå€¼
    
    fn __init__(inout self):
        """é»˜è®¤å‚æ•°"""
        self.time_decay_factor = 0.05
        self.attention_weight = 0.4
        self.frequency_weight = 0.3
        self.recency_weight = 0.3
        self.eviction_threshold = 0.2


struct MemoryPool:
    """å†…å­˜æ± ç®¡ç†"""
    var device_id: String
    var tier: Int
    var total_size: Int
    var used_size: Int
    var free_blocks: List[MemoryBlock]
    var allocated_blocks: Dict[String, MemoryBlock]
    var allocation_alignment: Int
    
    fn __init__(inout self, device_id: String, tier: Int, total_size: Int):
        """åˆå§‹åŒ–å†…å­˜æ± """
        self.device_id = device_id
        self.tier = tier
        self.total_size = total_size
        self.used_size = 0
        self.free_blocks = List[MemoryBlock]()
        self.allocated_blocks = Dict[String, MemoryBlock]()
        self.allocation_alignment = 256  # 256å­—èŠ‚å¯¹é½
    
    fn allocate(inout self, size: Int) -> Optional[MemoryBlock]:
        """åˆ†é…å†…å­˜å—"""
        aligned_size = self._align_size(size)
        
        if self.used_size + aligned_size > self.total_size:
            return None  # å†…å­˜ä¸è¶³
        
        # ç®€åŒ–å®ç°ï¼šç›´æ¥åˆ†é…
        if self.tier == GPU_TIER:
            ptr = self._allocate_gpu_memory(aligned_size)
        elif self.tier == CPU_TIER:
            ptr = self._allocate_cpu_memory(aligned_size)
        else:  # NVME_TIER
            ptr = self._allocate_nvme_memory(aligned_size)
        
        if ptr.is_null():
            return None
        
        # åˆ›å»ºå†…å­˜å—
        block = MemoryBlock(ptr, aligned_size, self.device_id, self.tier)
        self.allocated_blocks[block.block_id] = block
        self.used_size += aligned_size
        
        return block
    
    fn deallocate(inout self, block_id: String) -> Bool:
        """é‡Šæ”¾å†…å­˜å—"""
        if block_id not in self.allocated_blocks:
            return False
        
        block = self.allocated_blocks[block_id]
        
        # é‡Šæ”¾åº•å±‚å†…å­˜
        self._free_memory(block.ptr, block.size, block.tier)
        
        # æ›´æ–°ç»Ÿè®¡
        self.used_size -= block.size
        del self.allocated_blocks[block_id]
        
        return True
    
    fn get_memory_pressure(self) -> Float64:
        """è·å–å†…å­˜å‹åŠ›"""
        return Float64(self.used_size) / Float64(self.total_size)
    
    fn _align_size(self, size: Int) -> Int:
        """å†…å­˜å¯¹é½"""
        return ((size + self.allocation_alignment - 1) // self.allocation_alignment) * self.allocation_alignment
    
    fn _allocate_gpu_memory(self, size: Int) -> UnsafePointer[UInt8]:
        """åˆ†é…GPUå†…å­˜"""
        # ä½¿ç”¨ MAX Engine åˆ†é…GPUå†…å­˜
        try:
            address = engine.allocate_device_memory(self.device_id, size)
            if address is not None:
                return UnsafePointer[UInt8].address_of(address)
        except:
            pass
        return UnsafePointer[UInt8]()
    
    fn _allocate_cpu_memory(self, size: Int) -> UnsafePointer[UInt8]:
        """åˆ†é…CPUå†…å­˜ï¼ˆå›ºå®šé¡µé¢ï¼‰"""
        # ä½¿ç”¨ Python è°ƒç”¨ç³»ç»Ÿå†…å­˜åˆ†é…
        Python.add_to_path(".")
        ctypes = Python.import_module("ctypes")
        
        try:
            # åˆ†é…å›ºå®šé¡µé¢å†…å­˜
            ptr = ctypes.c_void_p()
            # è¿™é‡Œéœ€è¦è°ƒç”¨ CUDA cudaHostAlloc æˆ–ç±»ä¼¼API
            # ç®€åŒ–å®ç°
            address = id(ptr)
            return UnsafePointer[UInt8].address_of(address)
        except:
            return UnsafePointer[UInt8]()
    
    fn _allocate_nvme_memory(self, size: Int) -> UnsafePointer[UInt8]:
        """åˆ†é…NVMeæ˜ å°„å†…å­˜"""
        # å†…å­˜æ˜ å°„æ–‡ä»¶
        Python.add_to_path(".")
        mmap_module = Python.import_module("mmap")
        
        try:
            # åˆ›å»ºå†…å­˜æ˜ å°„æ–‡ä»¶
            file_path = f"/tmp/wicore_nvme_{self.device_id}_{time.time_ns()}"
            with open(file_path, "wb") as f:
                f.write(b'\x00' * size)
            
            # æ˜ å°„åˆ°å†…å­˜
            with open(file_path, "r+b") as f:
                mm = mmap_module.mmap(f.fileno(), size)
                address = id(mm)
                return UnsafePointer[UInt8].address_of(address)
        except:
            return UnsafePointer[UInt8]()
    
    fn _free_memory(self, ptr: UnsafePointer[UInt8], size: Int, tier: Int):
        """é‡Šæ”¾å†…å­˜"""
        if tier == GPU_TIER:
            # é‡Šæ”¾GPUå†…å­˜
            engine.free_device_memory(self.device_id, ptr.address, size)
        elif tier == CPU_TIER:
            # é‡Šæ”¾å›ºå®šé¡µé¢å†…å­˜
            pass  # Python GC ä¼šå¤„ç†
        else:  # NVME_TIER
            # å–æ¶ˆå†…å­˜æ˜ å°„
            pass  # Python GC ä¼šå¤„ç†


struct NVMeCache:
    """NVMe ç¼“å­˜ç®¡ç†"""
    var cache_path: String
    var max_cache_size: Int
    var current_cache_size: Int
    var cached_blocks: Dict[String, String]  # block_id -> file_path
    
    fn __init__(inout self, cache_path: String, max_size_gb: Int = 100):
        """åˆå§‹åŒ–NVMeç¼“å­˜"""
        self.cache_path = cache_path
        self.max_cache_size = max_size_gb * 1024 * 1024 * 1024
        self.current_cache_size = 0
        self.cached_blocks = Dict[String, String]()
        
        # åˆ›å»ºç¼“å­˜ç›®å½•
        self._ensure_cache_directory()
    
    fn store_block(inout self, block: MemoryBlock) -> Bool:
        """å­˜å‚¨å—åˆ°NVMe"""
        if self.current_cache_size + block.size > self.max_cache_size:
            # éœ€è¦æ¸…ç†ç©ºé—´
            if not self._cleanup_cache(block.size):
                return False
        
        file_path = self.cache_path + "/" + block.block_id + ".cache"
        
        # å°†å†…å­˜å—å†™å…¥æ–‡ä»¶
        if self._write_block_to_file(block, file_path):
            self.cached_blocks[block.block_id] = file_path
            self.current_cache_size += block.size
            return True
        
        return False
    
    fn load_block(self, block_id: String, target_device: String) -> Optional[MemoryBlock]:
        """ä»NVMeåŠ è½½å—"""
        if block_id not in self.cached_blocks:
            return None
        
        file_path = self.cached_blocks[block_id]
        return self._read_block_from_file(file_path, target_device)
    
    fn _ensure_cache_directory(self):
        """ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨"""
        Python.add_to_path(".")
        os_module = Python.import_module("os")
        
        try:
            os_module.makedirs(self.cache_path, exist_ok=True)
        except:
            print("âš ï¸  æ— æ³•åˆ›å»ºNVMeç¼“å­˜ç›®å½•:", self.cache_path)
    
    fn _cleanup_cache(inout self, required_size: Int) -> Bool:
        """æ¸…ç†ç¼“å­˜ç©ºé—´"""
        # ç®€åŒ–å®ç°ï¼šåˆ é™¤æœ€è€çš„æ–‡ä»¶
        # å®é™…åº”è¯¥åŸºäºè®¿é—®æ—¶é—´å’Œé‡è¦æ€§
        freed_size = 0
        
        for block_id in self.cached_blocks:
            if freed_size >= required_size:
                break
                
            file_path = self.cached_blocks[block_id]
            file_size = self._get_file_size(file_path)
            
            if self._delete_cache_file(file_path):
                del self.cached_blocks[block_id]
                freed_size += file_size
                self.current_cache_size -= file_size
        
        return freed_size >= required_size
    
    fn _write_block_to_file(self, block: MemoryBlock, file_path: String) -> Bool:
        """å†™å…¥å—åˆ°æ–‡ä»¶"""
        # ä½¿ç”¨ Python æ–‡ä»¶æ“ä½œ
        try:
            Python.add_to_path(".")
            
            # ä»å†…å­˜æŒ‡é’ˆè¯»å–æ•°æ®å¹¶å†™å…¥æ–‡ä»¶
            # è¿™é‡Œéœ€è¦å¤„ç† UnsafePointer åˆ° Python bytes çš„è½¬æ¢
            # ç®€åŒ–å®ç°
            with open(file_path, "wb") as f:
                # å†™å…¥å—å…ƒæ•°æ®
                metadata = {
                    "size": block.size,
                    "device_id": block.device_id,
                    "tier": block.tier,
                    "attention_score": block.attention_score
                }
                
                # å®é™…éœ€è¦å†™å…¥å†…å­˜æ•°æ®
                # data = ctypes.string_at(block.ptr.address, block.size)
                # f.write(data)
                
                # æ¨¡æ‹Ÿå†™å…¥
                f.write(b'\x00' * block.size)
            
            return True
        except:
            return False
    
    fn _read_block_from_file(self, file_path: String, target_device: String) -> Optional[MemoryBlock]:
        """ä»æ–‡ä»¶è¯»å–å—"""
        try:
            with open(file_path, "rb") as f:
                data = f.read()
                
                # åˆ›å»ºæ–°çš„å†…å­˜å—
                block = MemoryBlock()
                block.size = len(data)
                block.device_id = target_device
                block.tier = GPU_TIER  # åŠ è½½åˆ°GPUå±‚
                
                # åˆ†é…å†…å­˜å¹¶å¤åˆ¶æ•°æ®
                # è¿™é‡Œéœ€è¦å®é™…çš„å†…å­˜åˆ†é…å’Œæ•°æ®å¤åˆ¶
                
                return block
        except:
            return None
    
    fn _get_file_size(self, file_path: String) -> Int:
        """è·å–æ–‡ä»¶å¤§å°"""
        Python.add_to_path(".")
        os_module = Python.import_module("os")
        
        try:
            return int(os_module.path.getsize(file_path))
        except:
            return 0
    
    fn _delete_cache_file(self, file_path: String) -> Bool:
        """åˆ é™¤ç¼“å­˜æ–‡ä»¶"""
        Python.add_to_path(".")
        os_module = Python.import_module("os")
        
        try:
            os_module.remove(file_path)
            return True
        except:
            return False


struct HMTMemoryManager:
    """HMT åˆ†å±‚å†…å­˜ç®¡ç†å™¨ä¸»ç±»"""
    var device_manager: DeviceManager
    var gpu_pools: Dict[String, MemoryPool]      # GPUå†…å­˜æ± 
    var cpu_pool: MemoryPool                     # CPUå†…å­˜æ± 
    var nvme_cache: NVMeCache                    # NVMeç¼“å­˜
    var a2cr_params: A2CRParams                  # AÂ²CRå‚æ•°
    var migration_enabled: Bool                   # æ˜¯å¦å¯ç”¨è¿ç§»
    var total_allocations: Int                   # æ€»åˆ†é…æ¬¡æ•°
    var total_migrations: Int                    # æ€»è¿ç§»æ¬¡æ•°
    var cache_hits: Int                          # ç¼“å­˜å‘½ä¸­æ¬¡æ•°
    var cache_misses: Int                        # ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°
    
    fn __init__(inout self, device_manager: DeviceManager, config: WiCoreConfig):
        """åˆå§‹åŒ–HMTå†…å­˜ç®¡ç†å™¨"""
        print("ğŸ’¾ åˆå§‹åŒ– HMT åˆ†å±‚å†…å­˜ç®¡ç†å™¨...")
        
        self.device_manager = device_manager
        self.gpu_pools = Dict[String, MemoryPool]()
        self.migration_enabled = config.enable_a2cr
        self.total_allocations = 0
        self.total_migrations = 0
        self.cache_hits = 0
        self.cache_misses = 0
        
        # åˆå§‹åŒ–AÂ²CRå‚æ•°
        self.a2cr_params = A2CRParams()
        self.a2cr_params.time_decay_factor = config.time_decay_factor
        self.a2cr_params.attention_weight = config.attention_weight
        
        # åˆå§‹åŒ–NVMeç¼“å­˜
        self.nvme_cache = NVMeCache(config.nvme_cache_path)
        
        # å ä½ç¬¦CPUæ± åˆå§‹åŒ–
        self.cpu_pool = MemoryPool("cpu", CPU_TIER, 32 * 1024 * 1024 * 1024)  # 32GB
    
    fn initialize(inout self) -> Bool:
        """åˆå§‹åŒ–åˆ†å±‚å†…å­˜ç³»ç»Ÿ"""
        print("ğŸ”§ åˆå§‹åŒ–ä¸‰çº§å­˜å‚¨ç®¡ç†...")
        
        try:
            # ä¸ºæ¯ä¸ªGPUåˆ›å»ºå†…å­˜æ± 
            available_devices = self.device_manager.get_available_devices()
            
            for device_id in available_devices:
                device = self.device_manager._get_device_by_id(device_id)
                if device is None:
                    continue
                    
                device_info = device.value()
                
                if device_info.device_type == "gpu":
                    # åˆ›å»ºGPUå†…å­˜æ± 
                    memory_limit = int(device_info.memory_total * 0.9)  # ä½¿ç”¨90%å†…å­˜
                    pool = MemoryPool(device_id, GPU_TIER, memory_limit)
                    self.gpu_pools[device_id] = pool
                    print(f"âœ… åˆ›å»ºGPUå†…å­˜æ± : {device_id} ({memory_limit // (1024*1024*1024)}GB)")
            
            # åˆå§‹åŒ–CPUå†…å­˜æ± 
            cpu_memory = self._get_system_memory()
            self.cpu_pool = MemoryPool("cpu", CPU_TIER, cpu_memory)
            print(f"âœ… åˆ›å»ºCPUå†…å­˜æ± : {cpu_memory // (1024*1024*1024)}GB")
            
            # åˆå§‹åŒ–NVMeç¼“å­˜
            print(f"âœ… åˆå§‹åŒ–NVMeç¼“å­˜: {self.nvme_cache.cache_path}")
            
            print("âœ… HMT åˆ†å±‚å†…å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            print("âŒ HMTå†…å­˜ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥:", str(e))
            return False
    
    fn allocate_optimal(inout self, size: Int, usage_hint: String, 
                       attention_score: Float64 = 0.0) -> Optional[MemoryBlock]:
        """æ™ºèƒ½åˆ†é…å†…å­˜åˆ°æœ€ä¼˜ä½ç½®"""
        self.total_allocations += 1
        
        # AÂ²CRç®—æ³•å†³å®šæœ€ä¼˜åˆ†é…ä½ç½®
        optimal_device = self._select_optimal_device(size, usage_hint, attention_score)
        
        if optimal_device == "":
            print("âŒ æ— æ³•æ‰¾åˆ°åˆé€‚çš„è®¾å¤‡åˆ†é…å†…å­˜")
            return None
        
        # åœ¨æœ€ä¼˜è®¾å¤‡ä¸Šåˆ†é…å†…å­˜
        return self._allocate_on_device(optimal_device, size, attention_score)
    
    fn allocate_gpu_memory(inout self, device_id: String, size: Int) -> Optional[MemoryBlock]:
        """åœ¨æŒ‡å®šGPUä¸Šåˆ†é…å†…å­˜"""
        if device_id not in self.gpu_pools:
            print(f"âŒ GPUè®¾å¤‡ä¸å­˜åœ¨: {device_id}")
            return None
        
        pool = self.gpu_pools[device_id]
        return pool.allocate(size)
    
    fn migrate_async(inout self, block: MemoryBlock, target_device: String):
        """å¼‚æ­¥æ•°æ®è¿ç§»"""
        if not self.migration_enabled:
            return
        
        self.total_migrations += 1
        
        # åœ¨çœŸå®ç¯å¢ƒä¸­ï¼Œè¿™é‡Œä¼šå¯åŠ¨å¼‚æ­¥è¿ç§»çº¿ç¨‹
        # ç®€åŒ–å®ç°ï¼šåŒæ­¥è¿ç§»
        self._migrate_block_sync(block, target_device)
    
    fn prefetch_blocks(self, block_ids: List[String], target_device: String):
        """é¢„å–æ•°æ®å—"""
        for block_id in block_ids:
            # ä»NVMeç¼“å­˜é¢„å–åˆ°ç›®æ ‡è®¾å¤‡
            block = self.nvme_cache.load_block(block_id, target_device)
            if block is not None:
                self.cache_hits += 1
                print(f"âœ… é¢„å–æˆåŠŸ: {block_id} -> {target_device}")
            else:
                self.cache_misses += 1
                print(f"âš ï¸  é¢„å–å¤±è´¥: {block_id}")
    
    fn should_evict(self, block: MemoryBlock) -> Bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é©±é€å—"""
        if not self.migration_enabled:
            return False
        
        cache_score = block.calculate_cache_score(self.a2cr_params)
        
        # åŠ¨æ€é˜ˆå€¼ï¼šæ ¹æ®å†…å­˜å‹åŠ›è°ƒæ•´
        device_id = block.device_id
        memory_pressure = self._get_memory_pressure(device_id)
        dynamic_threshold = self.a2cr_params.eviction_threshold + 0.6 * memory_pressure
        
        return cache_score < dynamic_threshold
    
    fn cleanup(self):
        """æ¸…ç†å†…å­˜ç®¡ç†å™¨"""
        print("ğŸ’¾ æ¸…ç† HMT å†…å­˜ç®¡ç†å™¨...")
        
        # æ¸…ç†æ‰€æœ‰GPUå†…å­˜æ± 
        for device_id in self.gpu_pools:
            pool = self.gpu_pools[device_id]
            # é‡Šæ”¾æ‰€æœ‰åˆ†é…çš„å—
            for block_id in pool.allocated_blocks:
                pool.deallocate(block_id)
        
        # æ¸…ç†CPUå†…å­˜æ± 
        for block_id in self.cpu_pool.allocated_blocks:
            self.cpu_pool.deallocate(block_id)
        
        # æ¸…ç†ç»Ÿè®¡ä¿¡æ¯
        print(f"ğŸ“Š å†…å­˜ç®¡ç†ç»Ÿè®¡:")
        print(f"   æ€»åˆ†é…æ¬¡æ•°: {self.total_allocations}")
        print(f"   æ€»è¿ç§»æ¬¡æ•°: {self.total_migrations}")
        print(f"   ç¼“å­˜å‘½ä¸­ç‡: {self._calculate_cache_hit_rate():.2f}%")
        
        print("âœ… HMT å†…å­˜ç®¡ç†å™¨æ¸…ç†å®Œæˆ")
    
    fn get_memory_summary(self) -> String:
        """è·å–å†…å­˜ä½¿ç”¨æ‘˜è¦"""
        summary = "HMT å†…å­˜çŠ¶æ€:\\n"
        
        # GPUå†…å­˜çŠ¶æ€
        for device_id in self.gpu_pools:
            pool = self.gpu_pools[device_id]
            used_gb = Float64(pool.used_size) / (1024 * 1024 * 1024)
            total_gb = Float64(pool.total_size) / (1024 * 1024 * 1024)
            utilization = pool.get_memory_pressure() * 100
            
            summary += f"  GPU {device_id}: {used_gb:.1f}/{total_gb:.1f}GB ({utilization:.1f}%)\\n"
        
        # CPUå†…å­˜çŠ¶æ€
        cpu_used_gb = Float64(self.cpu_pool.used_size) / (1024 * 1024 * 1024)
        cpu_total_gb = Float64(self.cpu_pool.total_size) / (1024 * 1024 * 1024)
        cpu_utilization = self.cpu_pool.get_memory_pressure() * 100
        
        summary += f"  CPU: {cpu_used_gb:.1f}/{cpu_total_gb:.1f}GB ({cpu_utilization:.1f}%)\\n"
        
        # NVMeç¼“å­˜çŠ¶æ€
        nvme_used_gb = Float64(self.nvme_cache.current_cache_size) / (1024 * 1024 * 1024)
        nvme_max_gb = Float64(self.nvme_cache.max_cache_size) / (1024 * 1024 * 1024)
        
        summary += f"  NVMe: {nvme_used_gb:.1f}/{nvme_max_gb:.1f}GB\\n"
        summary += f"  ç¼“å­˜å‘½ä¸­ç‡: {self._calculate_cache_hit_rate():.1f}%"
        
        return summary
    
    # ç§æœ‰æ–¹æ³•
    fn _select_optimal_device(self, size: Int, usage_hint: String, 
                             attention_score: Float64) -> String:
        """AÂ²CRç®—æ³•é€‰æ‹©æœ€ä¼˜è®¾å¤‡"""
        best_device = ""
        best_score = -1.0
        
        # è¯„ä¼°æ‰€æœ‰å¯ç”¨è®¾å¤‡
        available_devices = self.device_manager.get_available_devices()
        
        for device_id in available_devices:
            device = self.device_manager._get_device_by_id(device_id)
            if device is None:
                continue
                
            device_info = device.value()
            
            # æ£€æŸ¥å†…å­˜æ˜¯å¦å……è¶³
            if not device_info.is_memory_sufficient(size):
                continue
            
            # è®¡ç®—è®¾å¤‡é€‚é…åˆ†æ•°
            score = self._calculate_device_score(device_info, size, usage_hint, attention_score)
            
            if score > best_score:
                best_score = score
                best_device = device_id
        
        return best_device
    
    fn _calculate_device_score(self, device: DeviceInfo, size: Int, 
                              usage_hint: String, attention_score: Float64) -> Float64:
        """è®¡ç®—è®¾å¤‡é€‚é…åˆ†æ•°"""
        # åŸºç¡€åˆ†æ•°ï¼šè®¡ç®—èƒ½åŠ›
        score = device.compute_capability
        
        # å†…å­˜å‹åŠ›æƒ©ç½š
        memory_pressure = device.get_memory_utilization()
        score *= (1.0 - memory_pressure * 0.5)
        
        # ä½¿ç”¨æç¤ºåŠ æƒ
        if "inference" in usage_hint or "attention" in usage_hint:
            if device.device_type == "gpu":
                score *= 2.0  # GPUæ›´é€‚åˆæ¨ç†
        
        # æ³¨æ„åŠ›åˆ†æ•°åŠ æƒ
        if attention_score > 0.5:
            if device.device_type == "gpu":
                score *= 1.5  # é«˜æ³¨æ„åŠ›åˆ†æ•°ä¼˜å…ˆGPU
        
        return score
    
    fn _allocate_on_device(inout self, device_id: String, size: Int, 
                          attention_score: Float64) -> Optional[MemoryBlock]:
        """åœ¨æŒ‡å®šè®¾å¤‡ä¸Šåˆ†é…å†…å­˜"""
        if "gpu" in device_id and device_id in self.gpu_pools:
            # GPUåˆ†é…
            pool = self.gpu_pools[device_id]
            block = pool.allocate(size)
            if block is not None:
                block.value().attention_score = attention_score
            return block
        elif "cpu" in device_id:
            # CPUåˆ†é…
            block = self.cpu_pool.allocate(size)
            if block is not None:
                block.value().attention_score = attention_score
            return block
        else:
            return None
    
    fn _migrate_block_sync(self, block: MemoryBlock, target_device: String):
        """åŒæ­¥è¿ç§»å—"""
        print(f"ğŸ”„ è¿ç§»å— {block.block_id}: {block.device_id} -> {target_device}")
        
        # ç®€åŒ–å®ç°ï¼š
        # 1. åœ¨ç›®æ ‡è®¾å¤‡åˆ†é…æ–°å†…å­˜
        # 2. å¤åˆ¶æ•°æ®
        # 3. é‡Šæ”¾æºå†…å­˜
        # 4. æ›´æ–°å—ä¿¡æ¯
        
        # å®é™…è¿ç§»é€»è¾‘ä¼šå¾ˆå¤æ‚ï¼Œéœ€è¦å¤„ç†ï¼š
        # - è·¨è®¾å¤‡å†…å­˜æ‹·è´
        # - å¼‚æ­¥æ“ä½œ
        # - é”™è¯¯å¤„ç†
        # - å¼•ç”¨æ›´æ–°
    
    fn _get_memory_pressure(self, device_id: String) -> Float64:
        """è·å–è®¾å¤‡å†…å­˜å‹åŠ›"""
        if "gpu" in device_id and device_id in self.gpu_pools:
            return self.gpu_pools[device_id].get_memory_pressure()
        elif "cpu" in device_id:
            return self.cpu_pool.get_memory_pressure()
        else:
            return 0.0
    
    fn _get_system_memory(self) -> Int:
        """è·å–ç³»ç»Ÿå†…å­˜å¤§å°"""
        # ä½¿ç”¨Pythonè·å–ç³»ç»Ÿå†…å­˜
        Python.add_to_path(".")
        psutil = Python.import_module("psutil")
        
        try:
            memory_info = psutil.virtual_memory()
            total_memory = int(memory_info.total)
            # ä½¿ç”¨80%çš„ç³»ç»Ÿå†…å­˜
            return int(total_memory * 0.8)
        except:
            # é»˜è®¤16GB
            return 16 * 1024 * 1024 * 1024
    
    fn _calculate_cache_hit_rate(self) -> Float64:
        """è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡"""
        total_requests = self.cache_hits + self.cache_misses
        if total_requests == 0:
            return 0.0
        return Float64(self.cache_hits) / Float64(total_requests) * 100.0 