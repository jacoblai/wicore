# WiCore Mojo æ¨ç†å¼•æ“

ğŸš€ **åŸºäº Mojo è¯­è¨€çš„è‡ªä¸»å¯æ§é«˜æ€§èƒ½ AI æ¨ç†å¼•æ“**

WiCore æ˜¯ä¸“ä¸ºä¸­å›½ç®—åŠ›å—é™ç¯å¢ƒè®¾è®¡çš„å¼‚æ„ç¡¬ä»¶ç»Ÿä¸€è°ƒåº¦æ¨ç†å¹³å°ï¼Œé›†æˆäº† HMT åˆ†å±‚å†…å­˜ç®¡ç†å’Œ MoR åŠ¨æ€è·¯ç”±æŠ€æœ¯ï¼Œæ”¯æŒåƒäº¿å‚æ•°æ¨¡å‹çš„é«˜æ•ˆæ¨ç†ã€‚

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### æŠ€æœ¯ä¼˜åŠ¿
- **ğŸ”’ è‡ªä¸»å¯æ§**: æ‘†è„± NVIDIA TensorRT ä¾èµ–ï¼Œé¿å…æŠ€æœ¯å°é”é£é™©
- **ğŸŒ ç¡¬ä»¶æ— å…³**: æ”¯æŒæ‰€æœ‰ GPU å“ç‰Œï¼ˆNVIDIAã€AMDã€Intelã€å›½äº§ç­‰ï¼‰
- **âš¡ æè‡´æ€§èƒ½**: Mojo 68,000x Python æ€§èƒ½ï¼ŒåŸç”Ÿç¡¬ä»¶ç¼–è¯‘ä¼˜åŒ–
- **ğŸ§  æ™ºèƒ½è°ƒåº¦**: HMT ä¸‰çº§å­˜å‚¨ + AÂ²CR ç¼“å­˜ç®—æ³• + MoR åŠ¨æ€è·¯ç”±
- **ğŸ”Œ ç”Ÿæ€å…¼å®¹**: 100% Python å…¼å®¹ï¼ŒOpenAI API æ ‡å‡†æ¥å£

### ç›®æ ‡æ€§èƒ½ (T10 åŒå¡)
- **ååé‡**: 100-150 tokens/s
- **å»¶è¿Ÿ**: 50-100ms (é¦– token)
- **å¹¶å‘**: 16-32 å¹¶å‘è¯·æ±‚
- **å†…å­˜åˆ©ç”¨ç‡**: >85%

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           WiCore Mojo Engine            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Web API Layer (FastAPI/Mojo)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Request Orchestrator (Mojo)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Compute Scheduler (MAX Engine)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚ â”‚Compute  â”‚ â”‚Compute  â”‚ â”‚Compute  â”‚     â”‚
â”‚ â”‚Node 1   â”‚ â”‚Node 2   â”‚ â”‚Node N   â”‚     â”‚
â”‚ â”‚(GPU/CPU)â”‚ â”‚(GPU/CPU)â”‚ â”‚(...)    â”‚     â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  HMT Memory Manager (Mojo + MAX)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Hardware Abstraction Layer (MAX)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”         â”‚
â”‚ â”‚T10#1â”‚ â”‚T10#2â”‚ â”‚ CPU â”‚ â”‚ ... â”‚         â”‚
â”‚ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶

1. **è®¾å¤‡ç®¡ç†å™¨** (`device_manager.mojo`)
   - å¼‚æ„ç¡¬ä»¶è®¾å¤‡å‘ç°å’ŒæŠ½è±¡
   - è®¾å¤‡æ‹“æ‰‘æ„å»ºå’Œå¸¦å®½ä¼˜åŒ–
   - NUMA æ„ŸçŸ¥çš„è®¾å¤‡ç»‘å®š

2. **HMT åˆ†å±‚å†…å­˜ç®¡ç†å™¨** (`hmt_memory_manager.mojo`)
   - GPU æ˜¾å­˜ â†’ CPU å†…å­˜ â†’ NVMe å­˜å‚¨ä¸‰çº§ç¼“å­˜
   - AÂ²CR (Attention-Aware Cache Replacement) æ™ºèƒ½ç½®æ¢ç®—æ³•
   - é›¶æ‹·è´å†…å­˜æ± å’Œå¼‚æ­¥æ•°æ®è¿ç§»

3. **æ¨¡å‹æ‰§è¡Œå™¨** (`model_executor.mojo`)
   - Gemma-3-27B æ¨¡å‹åŠ è½½å’Œæ¨ç†
   - MoR (Mixture of Routers) åŠ¨æ€è·¯ç”±
   - å¤š GPU åè°ƒå’Œæ‰¹å¤„ç†ä¼˜åŒ–

4. **è¯·æ±‚è°ƒåº¦å™¨** (`request_scheduler.mojo`)
   - ä¼˜å…ˆçº§é˜Ÿåˆ—å’Œæ™ºèƒ½æ‰¹å¤„ç†
   - å¼‚æ­¥æ‰§è¡Œå’Œè´Ÿè½½å‡è¡¡
   - è¶…æ—¶å¤„ç†å’Œé”™è¯¯æ¢å¤

5. **Web æœåŠ¡å™¨** (`web_server.mojo`)
   - OpenAI å…¼å®¹ API æ¥å£
   - æµå¼è¾“å‡ºå’Œå¥åº·ç›‘æ§
   - é«˜å¹¶å‘è¯·æ±‚å¤„ç†

## ğŸ› ï¸ å®‰è£…æŒ‡å—

### ç³»ç»Ÿè¦æ±‚

**å¼€å‘ç¯å¢ƒ** (macOS/Linux):
- Python 3.8+
- 8GB+ RAM
- æ”¯æŒæ¨¡æ‹Ÿæ¨¡å¼å¼€å‘

**ç”Ÿäº§ç¯å¢ƒ** (Linux):
- NVIDIA T10 åŒå¡ (æˆ–å…¶ä»– GPU)
- 64GB+ RAM
- NVMe SSD
- Modular SDK + MAX Engine

### å¿«é€Ÿå®‰è£…

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository_url>
cd wicore-mojo

# 2. è¿è¡Œç¯å¢ƒæ­å»ºè„šæœ¬
chmod +x scripts/setup.sh
./scripts/setup.sh

# 3. æ¿€æ´» Python ç¯å¢ƒ
source venv/bin/activate

# 4. è¿è¡Œæµ‹è¯•éªŒè¯
python scripts/test_engine.py
```

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

```bash
# 1. ä¸‹è½½ Gemma-3-27B æ¨¡å‹ï¼ˆè¯¦è§ä¸‹æ–¹æ¨¡å‹ä¸‹è½½æŒ‡å—ï¼‰
mkdir -p models
# æŒ‰ç…§æ¨¡å‹ä¸‹è½½æŒ‡å—ä¸‹è½½æ¨¡å‹æ–‡ä»¶

# 2. é…ç½®ç”Ÿäº§ç¯å¢ƒ
cp configs/development.json configs/production.json
# ç¼–è¾‘ production.json è®¾ç½® GPU é…ç½®

# 3. å¯åŠ¨æ¨ç†å¼•æ“
./scripts/start_engine.sh --config configs/production.json
```

## ğŸ“¦ æ¨¡å‹ä¸‹è½½æŒ‡å—

### æ”¯æŒçš„æ¨¡å‹

WiCore ç›®å‰ä¸»è¦æ”¯æŒä»¥ä¸‹æ¨¡å‹ï¼š

| æ¨¡å‹åç§° | å‚æ•°é‡ | å­˜å‚¨ç©ºé—´ | æ¨èç¡¬ä»¶ | çŠ¶æ€ |
|---------|-------|----------|----------|------|
| Gemma-3-27B-IT | 27B | ~54GB | T10 åŒå¡ | âœ… ä¸»è¦æ”¯æŒ |
| Gemma-3-9B-IT | 9B | ~18GB | T10 å•å¡ | ğŸ”„ å¼€å‘ä¸­ |
| Llama-3.1-8B | 8B | ~16GB | T10 å•å¡ | ğŸ”„ å¼€å‘ä¸­ |

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨ Hugging Face Hubï¼ˆæ¨èï¼‰

```bash
# å®‰è£… huggingface-hub
pixi add huggingface-hub

# ä¸‹è½½ Gemma-3-27B-IT æ¨¡å‹
cd models
pixi run python -c "
from huggingface_hub import snapshot_download
import os

# åˆ›å»ºæ¨¡å‹ç›®å½•
os.makedirs('gemma-3-27b-it', exist_ok=True)

# ä¸‹è½½æ¨¡å‹æ–‡ä»¶
snapshot_download(
    repo_id='google/gemma-2-27b-it',
    cache_dir='./cache',
    local_dir='./gemma-3-27b-it',
    local_dir_use_symlinks=False,
    resume_download=True
)

print('âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ')
"
```

### æ–¹æ³•äºŒï¼šä½¿ç”¨ Git LFS

```bash
# å®‰è£… Git LFS
sudo apt install git-lfs  # Ubuntu/Debian
# æˆ– brew install git-lfs  # macOS

# åˆå§‹åŒ– Git LFS
git lfs install

# å…‹éš†æ¨¡å‹ä»“åº“
cd models
git clone https://huggingface.co/google/gemma-2-27b-it gemma-3-27b-it

# éªŒè¯ä¸‹è½½å®Œæ•´æ€§
cd gemma-3-27b-it
git lfs ls-files  # æŸ¥çœ‹ LFS æ–‡ä»¶åˆ—è¡¨
```

### æ–¹æ³•ä¸‰ï¼šæ‰‹åŠ¨ä¸‹è½½ï¼ˆé€‚ç”¨äºç¦»çº¿ç¯å¢ƒï¼‰

å¦‚æœæ— æ³•ç›´æ¥è®¿é—® Hugging Faceï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–æ¨¡å‹ï¼š

1. **é€šè¿‡é•œåƒç«™ä¸‹è½½**ï¼š
```bash
# ä½¿ç”¨å›½å†…é•œåƒï¼ˆå¦‚ ModelScopeï¼‰
cd models
git clone https://modelscope.cn/google/gemma-2-27b-it.git gemma-3-27b-it
```

2. **åˆ†å—ä¸‹è½½**ï¼š
```bash
# ä½¿ç”¨ wget åˆ†å—ä¸‹è½½ï¼ˆé€‚ç”¨äºç½‘ç»œä¸ç¨³å®šçš„æƒ…å†µï¼‰
cd models/gemma-3-27b-it
wget -c https://huggingface.co/google/gemma-2-27b-it/resolve/main/model-00001-of-00109.safetensors
wget -c https://huggingface.co/google/gemma-2-27b-it/resolve/main/model-00002-of-00109.safetensors
# ... ç»§ç»­ä¸‹è½½æ‰€æœ‰åˆ†ç‰‡æ–‡ä»¶
```

### æ¨¡å‹æ–‡ä»¶ç»“æ„éªŒè¯

ä¸‹è½½å®Œæˆåï¼ŒéªŒè¯æ¨¡å‹æ–‡ä»¶ç»“æ„ï¼š

```bash
cd models/gemma-3-27b-it
ls -la

# æœŸæœ›çš„æ–‡ä»¶ç»“æ„ï¼š
# config.json                    # æ¨¡å‹é…ç½®
# generation_config.json         # ç”Ÿæˆé…ç½®  
# model-00001-of-00109.safetensors  # æ¨¡å‹æƒé‡ï¼ˆåˆ†ç‰‡1ï¼‰
# model-00002-of-00109.safetensors  # æ¨¡å‹æƒé‡ï¼ˆåˆ†ç‰‡2ï¼‰
# ...
# model-00109-of-00109.safetensors  # æ¨¡å‹æƒé‡ï¼ˆåˆ†ç‰‡109ï¼‰
# model.safetensors.index.json    # æƒé‡ç´¢å¼•
# special_tokens_map.json         # ç‰¹æ®Štokenæ˜ å°„
# tokenizer.json                  # åˆ†è¯å™¨
# tokenizer_config.json          # åˆ†è¯å™¨é…ç½®
```

### éªŒè¯æ¨¡å‹å®Œæ•´æ€§

è¿è¡Œä»¥ä¸‹è„šæœ¬éªŒè¯æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§ï¼š

```bash
# åˆ›å»ºéªŒè¯è„šæœ¬
cat > verify_model.py << 'EOF'
import os
import json
from pathlib import Path

def verify_gemma_model(model_path):
    """éªŒè¯ Gemma æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§"""
    model_path = Path(model_path)
    
    # å¿…éœ€æ–‡ä»¶åˆ—è¡¨
    required_files = [
        'config.json',
        'generation_config.json', 
        'model.safetensors.index.json',
        'special_tokens_map.json',
        'tokenizer.json',
        'tokenizer_config.json'
    ]
    
    print(f"ğŸ” éªŒè¯æ¨¡å‹ç›®å½•: {model_path}")
    
    # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
    missing_files = []
    for file in required_files:
        if not (model_path / file).exists():
            missing_files.append(file)
    
    if missing_files:
        print(f"âŒ ç¼ºå°‘æ–‡ä»¶: {missing_files}")
        return False
    
    # æ£€æŸ¥æƒé‡æ–‡ä»¶
    try:
        with open(model_path / 'model.safetensors.index.json', 'r') as f:
            index = json.load(f)
        
        weight_files = set(index['weight_map'].values())
        
        missing_weights = []
        for weight_file in weight_files:
            if not (model_path / weight_file).exists():
                missing_weights.append(weight_file)
        
        if missing_weights:
            print(f"âŒ ç¼ºå°‘æƒé‡æ–‡ä»¶: {missing_weights[:5]}...")  # åªæ˜¾ç¤ºå‰5ä¸ª
            return False
        
        print(f"âœ… æ‰¾åˆ° {len(weight_files)} ä¸ªæƒé‡æ–‡ä»¶")
        
    except Exception as e:
        print(f"âŒ éªŒè¯æƒé‡æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False
    
    # è®¡ç®—æ€»å¤§å°
    total_size = sum(f.stat().st_size for f in model_path.rglob('*') if f.is_file())
    total_size_gb = total_size / (1024**3)
    
    print(f"ğŸ“Š æ¨¡å‹æ€»å¤§å°: {total_size_gb:.1f} GB")
    
    if total_size_gb < 50:  # Gemma-3-27B åº”è¯¥å¤§çº¦ 54GB
        print("âš ï¸  æ¨¡å‹å¤§å°å¼‚å¸¸ï¼Œå¯èƒ½ä¸‹è½½ä¸å®Œæ•´")
        return False
    
    print("âœ… æ¨¡å‹éªŒè¯é€šè¿‡")
    return True

if __name__ == "__main__":
    model_path = "gemma-3-27b-it"
    verify_gemma_model(model_path)
EOF

# è¿è¡ŒéªŒè¯
pixi run python verify_model.py
```

### å­˜å‚¨ç©ºé—´è¦æ±‚

**ç£ç›˜ç©ºé—´å»ºè®®**ï¼š
- **Gemma-3-27B**: è‡³å°‘ 60GB å¯ç”¨ç©ºé—´ï¼ˆæ¨¡å‹ 54GB + ç¼“å­˜ 6GBï¼‰
- **ç³»ç»Ÿæ€»è®¡**: å»ºè®® 100GB+ è‡ªç”±ç©ºé—´ç”¨äºè¿è¡Œæ—¶ç¼“å­˜

**å­˜å‚¨æ€§èƒ½å»ºè®®**ï¼š
- ç”Ÿäº§ç¯å¢ƒï¼šNVMe SSDï¼ˆè¯»å–é€Ÿåº¦ >3GB/sï¼‰
- å¼€å‘ç¯å¢ƒï¼šæ™®é€š SSD å³å¯
- é¿å…ä½¿ç”¨æœºæ¢°ç¡¬ç›˜ï¼ˆHDDï¼‰

### ç¯å¢ƒå˜é‡é…ç½®

ä¸‹è½½å®Œæˆåï¼Œè®¾ç½®æ¨¡å‹è·¯å¾„ï¼š

```bash
# åœ¨ ~/.bashrc æˆ– ~/.zshrc ä¸­æ·»åŠ 
export WICORE_MODEL_PATH="/path/to/models/gemma-3-27b-it"

# æˆ–åœ¨é¡¹ç›®é…ç½®æ–‡ä»¶ä¸­è®¾ç½®
echo '{
  "model_path": "models/gemma-3-27b-it",
  "model_name": "gemma-3-27b-it"
}' > configs/model_config.json
```

### å¸¸è§é—®é¢˜

**Q: ä¸‹è½½é€Ÿåº¦å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ**
A: 
1. ä½¿ç”¨å›½å†…é•œåƒç«™ï¼ˆModelScopeï¼‰
2. ä½¿ç”¨æ–­ç‚¹ç»­ä¼ å·¥å…·ï¼ˆwget -cï¼‰
3. è€ƒè™‘åœ¨ç½‘ç»œå¥½çš„ç¯å¢ƒä¸‹è½½åä¼ è¾“

**Q: ç£ç›˜ç©ºé—´ä¸è¶³æ€ä¹ˆåŠï¼Ÿ**
A:
1. ä½¿ç”¨ç¬¦å·é“¾æ¥å°†æ¨¡å‹æ”¾åœ¨å¤§å®¹é‡ç£ç›˜ä¸Š
2. è€ƒè™‘ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ï¼ˆGemma-3-9Bï¼‰
3. æ¸…ç†ä¸å¿…è¦çš„ç¼“å­˜æ–‡ä»¶

**Q: æ¨¡å‹éªŒè¯å¤±è´¥æ€ä¹ˆåŠï¼Ÿ**
A:
1. é‡æ–°ä¸‹è½½ç¼ºå¤±çš„æ–‡ä»¶
2. æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œå­˜å‚¨è®¾å¤‡
3. å¯¹æ¯” SHA256 æ ¡éªŒå’Œ

## ğŸš€ ä½¿ç”¨æŒ‡å—

### API æ¥å£

WiCore æä¾› OpenAI å…¼å®¹çš„ REST APIï¼š

```bash
# èŠå¤©å®Œæˆ
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemma-3-27b-it",
    "messages": [
      {"role": "user", "content": "è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†"}
    ],
    "max_tokens": 512,
    "temperature": 0.7
  }'

# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# ç³»ç»ŸçŠ¶æ€
curl http://localhost:8000/status
```

### Python å®¢æˆ·ç«¯

```python
import requests

def chat_with_wicore(message: str) -> str:
    response = requests.post("http://localhost:8000/v1/chat/completions", 
        json={
            "model": "gemma-3-27b-it",
            "messages": [{"role": "user", "content": message}],
            "max_tokens": 512
        })
    
    return response.json()["choices"][0]["message"]["content"]

# ä½¿ç”¨ç¤ºä¾‹
result = chat_with_wicore("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
print(result)
```

## ğŸ“Š æ€§èƒ½è°ƒä¼˜

### HMT å†…å­˜ç®¡ç†é…ç½®

```json
{
  "hmt_config": {
    "enable_a2cr": true,
    "nvme_cache_path": "/nvme/wicore_cache",
    "time_decay_factor": 0.05,
    "attention_weight": 0.4,
    "frequency_weight": 0.3,
    "recency_weight": 0.3
  }
}
```

### MoR åŠ¨æ€è·¯ç”±é…ç½®

```json
{
  "mor_config": {
    "enable_mor_routing": true,
    "routing_threshold": 0.5,
    "cpu_depth": 8,
    "gpu_depth": 32
  }
}
```

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### å¼€å‘ç¯å¢ƒæµ‹è¯•

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
python scripts/test_engine.py

# å•ç‹¬æµ‹è¯•ç»„ä»¶
python scripts/test_device_manager.py
python scripts/test_memory_manager.py
python scripts/test_model_executor.py
```

### ç”Ÿäº§ç¯å¢ƒåŸºå‡†æµ‹è¯•

```bash
# æ€§èƒ½åŸºå‡†æµ‹è¯•
python scripts/benchmark.py --config configs/production.json

# å‹åŠ›æµ‹è¯•
python scripts/stress_test.py --concurrent 32 --duration 300

# å†…å­˜æ³„æ¼æ£€æµ‹
python scripts/memory_leak_test.py --iterations 1000
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
wicore-mojo/
â”œâ”€â”€ src/                           # Mojo æºä»£ç 
â”‚   â”œâ”€â”€ wicore_engine.mojo        # ä¸»å¼•æ“
â”‚   â”œâ”€â”€ device_manager.mojo       # è®¾å¤‡ç®¡ç†
â”‚   â”œâ”€â”€ hmt_memory_manager.mojo   # HMT å†…å­˜ç®¡ç†
â”‚   â”œâ”€â”€ model_executor.mojo       # æ¨¡å‹æ‰§è¡Œ
â”‚   â”œâ”€â”€ request_scheduler.mojo    # è¯·æ±‚è°ƒåº¦
â”‚   â””â”€â”€ web_server.mojo          # Web æœåŠ¡
â”œâ”€â”€ simulation/                   # æ¨¡æ‹Ÿç¯å¢ƒ
â”‚   â””â”€â”€ max_simulation.py        # MAX Engine æ¨¡æ‹Ÿ
â”œâ”€â”€ scripts/                     # è„šæœ¬å·¥å…·
â”‚   â”œâ”€â”€ setup.sh                # ç¯å¢ƒæ­å»º
â”‚   â”œâ”€â”€ test_engine.py          # æµ‹è¯•è„šæœ¬
â”‚   â””â”€â”€ benchmark.py            # æ€§èƒ½æµ‹è¯•
â”œâ”€â”€ configs/                    # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ development.json       # å¼€å‘é…ç½®
â”‚   â””â”€â”€ production.json        # ç”Ÿäº§é…ç½®
â”œâ”€â”€ models/                    # æ¨¡å‹æ–‡ä»¶
â”‚   â””â”€â”€ gemma-3-27b-it/       # Gemma-3 æ¨¡å‹
â”œâ”€â”€ docs/                     # æ–‡æ¡£
â””â”€â”€ requirements.txt          # Python ä¾èµ–
```

## ğŸ›¡ï¸ æŠ€æœ¯æ–¹æ¡ˆ

### å…³é”®æŠ€æœ¯å†³ç­–

1. **Mojo è¯­è¨€é€‰æ‹©**
   - 68,000x Python æ€§èƒ½æå‡
   - åŸç”Ÿç¡¬ä»¶ç¼–è¯‘ä¼˜åŒ–
   - Python ç”Ÿæ€å®Œå…¨å…¼å®¹

2. **HMT åˆ†å±‚å†…å­˜ç®¡ç†**
   - GPU æ˜¾å­˜ï¼šçƒ­æ•°æ® FP16 å­˜å‚¨
   - CPU å†…å­˜ï¼šæ¸©æ•°æ® Q8_K é‡åŒ–
   - NVMe å­˜å‚¨ï¼šå†·æ•°æ® Q4_K å‹ç¼©

3. **AÂ²CR ç¼“å­˜ç®—æ³•**
   - æ³¨æ„åŠ›æ„ŸçŸ¥çš„æ™ºèƒ½ç½®æ¢
   - æ—¶é—´è¡°å‡ + é¢‘ç‡ç»Ÿè®¡
   - åŠ¨æ€é˜ˆå€¼è‡ªé€‚åº”è°ƒæ•´

4. **MoR åŠ¨æ€è·¯ç”±**
   - è½»é‡çº§è·¯ç”±å†³ç­– (<3Î¼s)
   - é‡è¦ token â†’ GPU æ·±åº¦è®¡ç®—
   - æ™®é€š token â†’ CPU æµ…å±‚å¤„ç†

### é£é™©æ§åˆ¶

- **æŠ€æœ¯é£é™©**: ä¿æŒ Python å…¼å®¹æ€§ï¼Œæ¸è¿›å¼ Mojo é‡‡ç”¨
- **æ€§èƒ½é£é™©**: æ—©æœŸéªŒè¯ï¼Œå¤šåç«¯æ”¯æŒ
- **ç¡¬ä»¶é£é™©**: åˆ†å±‚æ”¯æŒï¼ŒCPU fallback æœºåˆ¶

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. åˆ›å»º Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ¯ è·¯çº¿å›¾

### Phase 1: åŸºç¡€éªŒè¯ âœ…
- [x] Mojo ç¯å¢ƒæ­å»º
- [x] æ¨¡æ‹Ÿç¯å¢ƒå¼€å‘
- [x] æ ¸å¿ƒç»„ä»¶å®ç°
- [x] é›†æˆæµ‹è¯•éªŒè¯

### Phase 2: ç”Ÿäº§å°±ç»ª ğŸ”„
- [ ] GPU æœåŠ¡å™¨éƒ¨ç½²
- [ ] Gemma-3-27B æ¨¡å‹åŠ è½½
- [ ] T10 åŒå¡æ€§èƒ½ä¼˜åŒ–
- [ ] ç¨³å®šæ€§æµ‹è¯•

### Phase 3: æ‰©å±•æ”¯æŒ ğŸ“‹
- [ ] å¤šæ¨¡å‹æ”¯æŒ
- [ ] å›½äº§ç¡¬ä»¶é€‚é…
- [ ] äº‘åŸç”Ÿéƒ¨ç½²
- [ ] ç›‘æ§å‘Šè­¦ç³»ç»Ÿ

---

**ğŸ‰ WiCore Mojo æ¨ç†å¼•æ“ - è‡ªä¸»å¯æ§çš„ AI æ¨ç†æœªæ¥** 

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·åˆ›å»º Issue æˆ–è”ç³»å¼€å‘å›¢é˜Ÿã€‚ 