"""
WiCoreé€šç”¨è®¾å¤‡ç®¡ç†å™¨
è®¾å¤‡æ— å…³çš„ç¡¬ä»¶èƒ½åŠ›å‘ç°å’Œä¼˜åŒ–æ¡†æ¶

æ ¸å¿ƒè®¾è®¡åŸåˆ™:
- ç¡¬ä»¶æ— å…³ï¼šè‡ªåŠ¨é€‚é…ä»»æ„GPUé…ç½®
- è¿è¡Œæ—¶å‘ç°ï¼šåŠ¨æ€æ£€æµ‹è®¾å¤‡èƒ½åŠ›å’Œæ‹“æ‰‘
- å¯æ‰©å±•æ¶æ„ï¼šæ’ä»¶å¼ä¼˜åŒ–ç­–ç•¥
- è‡ªé€‚åº”ä¼˜åŒ–ï¼šæ ¹æ®å®é™…ç¡¬ä»¶é€‰æ‹©æœ€ä¼˜ç­–ç•¥
"""

import torch
import logging
from typing import Dict, List, Optional, Tuple, Any, Set
from dataclasses import dataclass
from enum import Enum
import time
import threading
from collections import defaultdict
import psutil

logger = logging.getLogger(__name__)


class DeviceType(Enum):
    """è®¾å¤‡ç±»å‹"""
    GPU = "gpu"
    CPU = "cpu" 
    DISK = "disk"
    NETWORK = "network"


class InterconnectType(Enum):
    """äº’è”ç±»å‹"""
    PCIE = "pcie"
    NVLINK = "nvlink" 
    P2P = "p2p"
    SYSTEM_MEMORY = "system_memory"
    NETWORK = "network"


@dataclass
class DeviceCapability:
    """è®¾å¤‡èƒ½åŠ›æè¿°"""
    device_id: str
    device_type: DeviceType
    compute_capability: float
    memory_total: int
    memory_bandwidth: float  # GB/s
    compute_units: int
    frequency: float  # MHz
    supports_fp16: bool = True
    supports_bf16: bool = False
    supports_int8: bool = True
    power_limit: float = 0.0  # Watts
    thermal_limit: float = 85.0  # Celsius


@dataclass
class InterconnectInfo:
    """è®¾å¤‡äº’è”ä¿¡æ¯"""
    src_device: str
    dst_device: str
    interconnect_type: InterconnectType
    bandwidth: float  # GB/s
    latency: float = 0.0  # microseconds
    bidirectional: bool = True


@dataclass
class DeviceTopology:
    """è®¾å¤‡æ‹“æ‰‘ç»“æ„"""
    devices: Dict[str, DeviceCapability]
    interconnects: List[InterconnectInfo]
    numa_nodes: Dict[str, int]
    
    def get_bandwidth(self, src: str, dst: str) -> float:
        """è·å–ä¸¤è®¾å¤‡é—´å¸¦å®½"""
        for interconnect in self.interconnects:
            if ((interconnect.src_device == src and interconnect.dst_device == dst) or
                (interconnect.bidirectional and 
                 interconnect.src_device == dst and interconnect.dst_device == src)):
                return interconnect.bandwidth
        return 0.0
    
    def get_optimal_path(self, src: str, dst: str) -> List[str]:
        """è·å–æœ€ä¼˜ä¼ è¾“è·¯å¾„"""
        # ç®€åŒ–å®ç°ï¼šç›´æ¥è¿æ¥æˆ–é€šè¿‡ç³»ç»Ÿå†…å­˜
        if self.get_bandwidth(src, dst) > 0:
            return [src, dst]
        else:
            # é€šè¿‡ç³»ç»Ÿå†…å­˜ä¸­è½¬
            return [src, "system_memory", dst]


class UniversalDeviceManager:
    """é€šç”¨è®¾å¤‡ç®¡ç†å™¨
    
    è‡ªåŠ¨å‘ç°å’Œç®¡ç†ä»»æ„ç¡¬ä»¶é…ç½®çš„é€šç”¨æ¡†æ¶ï¼š
    - è¿è¡Œæ—¶ç¡¬ä»¶èƒ½åŠ›æ£€æµ‹
    - åŠ¨æ€æ‹“æ‰‘å‘ç°
    - è‡ªé€‚åº”ä¼˜åŒ–ç­–ç•¥é€‰æ‹©
    - è®¾å¤‡æ— å…³çš„è´Ÿè½½å‡è¡¡
    """
    
    def __init__(self):
        """åˆå§‹åŒ–é€šç”¨è®¾å¤‡ç®¡ç†å™¨"""
        self.device_topology: Optional[DeviceTopology] = None
        self.optimization_strategies: Dict[str, Any] = {}
        self.performance_history: Dict[str, List[float]] = defaultdict(list)
        
        # åŠ¨æ€ç›‘æ§
        self.monitoring_enabled = False
        self.monitoring_thread: Optional[threading.Thread] = None
        self._monitor_lock = threading.Lock()
        
        # è‡ªåŠ¨å‘ç°ç¡¬ä»¶
        self._discover_hardware()
        
        logger.info("é€šç”¨è®¾å¤‡ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _discover_hardware(self):
        """è‡ªåŠ¨å‘ç°ç¡¬ä»¶é…ç½®"""
        logger.info("ğŸ” è‡ªåŠ¨å‘ç°ç¡¬ä»¶é…ç½®...")
        
        devices = {}
        interconnects = []
        
        # å‘ç°GPUè®¾å¤‡
        gpu_devices = self._discover_gpu_devices()
        devices.update(gpu_devices)
        
        # å‘ç°CPUè®¾å¤‡
        cpu_devices = self._discover_cpu_devices()
        devices.update(cpu_devices)
        
        # å‘ç°è®¾å¤‡äº’è”
        interconnects.extend(self._discover_gpu_interconnects(gpu_devices))
        interconnects.extend(self._discover_system_interconnects(devices))
        
        # NUMAæ‹“æ‰‘
        numa_nodes = self._discover_numa_topology(devices)
        
        self.device_topology = DeviceTopology(
            devices=devices,
            interconnects=interconnects,
            numa_nodes=numa_nodes
        )
        
        self._log_topology_summary()
    
    def _discover_gpu_devices(self) -> Dict[str, DeviceCapability]:
        """å‘ç°GPUè®¾å¤‡"""
        gpu_devices = {}
        
        for i in range(torch.cuda.device_count()):
            try:
                props = torch.cuda.get_device_properties(i)
                
                # æ£€æµ‹ç²¾åº¦æ”¯æŒ
                supports_bf16 = hasattr(torch, 'bfloat16') and torch.cuda.is_bf16_supported()
                
                # å…¼å®¹æ€§å¤„ç†ï¼šè·å–æ—¶é’Ÿé¢‘ç‡
                try:
                    frequency = props.max_clock_rate / 1000.0  # Convert to MHz
                except AttributeError:
                    # åœ¨æŸäº›PyTorchç‰ˆæœ¬ä¸­ï¼Œä½¿ç”¨ä¸åŒçš„å±æ€§å
                    frequency = getattr(props, 'clock_rate', 1500.0) / 1000.0
                
                device_id = f"cuda:{i}"
                capability = DeviceCapability(
                    device_id=device_id,
                    device_type=DeviceType.GPU,
                    compute_capability=props.major + props.minor * 0.1,
                    memory_total=props.total_memory,
                    memory_bandwidth=self._estimate_memory_bandwidth(props),
                    compute_units=props.multi_processor_count,
                    frequency=frequency,
                    supports_fp16=True,
                    supports_bf16=supports_bf16,
                    supports_int8=True,
                    power_limit=self._get_gpu_power_limit(i),
                    thermal_limit=self._get_gpu_thermal_limit(i)
                )
                
                gpu_devices[device_id] = capability
                logger.info(f"å‘ç°GPU: {device_id} - {props.name}")
                
            except Exception as e:
                logger.warning(f"å‘ç°GPU {i} å¤±è´¥: {e}")
        
        return gpu_devices
    
    def _discover_cpu_devices(self) -> Dict[str, DeviceCapability]:
        """å‘ç°CPUè®¾å¤‡"""
        try:
            cpu_count = psutil.cpu_count(logical=False)
            cpu_freq = psutil.cpu_freq()
            memory_info = psutil.virtual_memory()
            
            device_id = "cpu"
            capability = DeviceCapability(
                device_id=device_id,
                device_type=DeviceType.CPU,
                compute_capability=1.0,  # æ ‡å‡†åŒ–ä¸º1.0
                memory_total=memory_info.total,
                memory_bandwidth=50.0,  # ä¼°ç®—CPUå†…å­˜å¸¦å®½
                compute_units=cpu_count,
                frequency=cpu_freq.current if cpu_freq else 2000.0,
                supports_fp16=False,  # CPUé€šå¸¸ä½¿ç”¨FP32
                supports_bf16=False,
                supports_int8=True
            )
            
            logger.info(f"å‘ç°CPU: {cpu_count}æ ¸å¿ƒ, {memory_info.total//1024**3}GBå†…å­˜")
            return {device_id: capability}
            
        except Exception as e:
            logger.warning(f"å‘ç°CPUå¤±è´¥: {e}")
            return {}
    
    def _discover_gpu_interconnects(self, gpu_devices: Dict[str, DeviceCapability]) -> List[InterconnectInfo]:
        """å‘ç°GPUé—´äº’è”"""
        interconnects = []
        gpu_ids = [int(dev.split(':')[1]) for dev in gpu_devices.keys() if dev.startswith('cuda:')]
        
        for i, gpu_a in enumerate(gpu_ids):
            for gpu_b in gpu_ids[i+1:]:
                try:
                    # æ£€æµ‹P2Pæ”¯æŒ
                    if torch.cuda.can_device_access_peer(gpu_a, gpu_b):
                        # æµ‹é‡P2På¸¦å®½
                        bandwidth = self._measure_p2p_bandwidth(gpu_a, gpu_b)
                        interconnect_type = InterconnectType.P2P
                        
                        if bandwidth > 100.0:  # é«˜å¸¦å®½ï¼Œå¯èƒ½æ˜¯NVLink
                            interconnect_type = InterconnectType.NVLINK
                        
                        interconnects.append(InterconnectInfo(
                            src_device=f"cuda:{gpu_a}",
                            dst_device=f"cuda:{gpu_b}",
                            interconnect_type=interconnect_type,
                            bandwidth=bandwidth,
                            bidirectional=True
                        ))
                        
                        logger.info(f"å‘ç°GPUäº’è”: cuda:{gpu_a} <-> cuda:{gpu_b} ({bandwidth:.1f} GB/s)")
                    
                except Exception as e:
                    logger.warning(f"æ£€æµ‹GPU {gpu_a}-{gpu_b} äº’è”å¤±è´¥: {e}")
        
        return interconnects
    
    def _discover_system_interconnects(self, devices: Dict[str, DeviceCapability]) -> List[InterconnectInfo]:
        """å‘ç°ç³»ç»Ÿçº§äº’è”"""
        interconnects = []
        
        # æ‰€æœ‰è®¾å¤‡éƒ½é€šè¿‡ç³»ç»Ÿæ€»çº¿è¿æ¥åˆ°CPU/ç³»ç»Ÿå†…å­˜
        cpu_bandwidth = 20.0  # ä¼°ç®—PCIeå¸¦å®½
        
        for device_id in devices.keys():
            if device_id != "cpu":
                interconnects.append(InterconnectInfo(
                    src_device=device_id,
                    dst_device="cpu",
                    interconnect_type=InterconnectType.PCIE,
                    bandwidth=cpu_bandwidth,
                    bidirectional=True
                ))
        
        return interconnects
    
    def _discover_numa_topology(self, devices: Dict[str, DeviceCapability]) -> Dict[str, int]:
        """å‘ç°NUMAæ‹“æ‰‘"""
        numa_nodes = {}
        
        # ç®€åŒ–å®ç°ï¼šæ‰€æœ‰è®¾å¤‡åˆ†é…åˆ°NUMAèŠ‚ç‚¹0
        for device_id in devices.keys():
            numa_nodes[device_id] = 0
        
        return numa_nodes
    
    def _estimate_memory_bandwidth(self, props) -> float:
        """ä¼°ç®—GPUå†…å­˜å¸¦å®½"""
        # åŸºäºGPUå‹å·å’Œè§„æ ¼ä¼°ç®—
        if "A100" in props.name:
            return 1555.0  # A100çš„HBM2eå¸¦å®½
        elif "V100" in props.name:
            return 900.0   # V100çš„HBM2å¸¦å®½
        elif "RTX" in props.name:
            return 800.0   # RTXç³»åˆ—çš„GDDR6Xå¸¦å®½
        elif "GTX" in props.name:
            return 400.0   # GTXç³»åˆ—çš„GDDR5å¸¦å®½
        else:
            # åŸºäºå†…å­˜å¤§å°ç²—ç•¥ä¼°ç®—
            memory_gb = props.total_memory / (1024**3)
            return min(memory_gb * 50, 1000.0)  # ä¿å®ˆä¼°ç®—
    
    def _get_gpu_power_limit(self, gpu_id: int) -> float:
        """è·å–GPUåŠŸè€—é™åˆ¶"""
        try:
            # è¿™é‡Œåº”è¯¥ä½¿ç”¨nvidia-ml-pyï¼Œç®€åŒ–è¿”å›ä¼°ç®—å€¼
            props = torch.cuda.get_device_properties(gpu_id)
            if "A100" in props.name:
                return 400.0
            elif "V100" in props.name:
                return 300.0
            else:
                return 250.0
        except:
            return 250.0
    
    def _get_gpu_thermal_limit(self, gpu_id: int) -> float:
        """è·å–GPUæ¸©åº¦é™åˆ¶"""
        try:
            # å¤§å¤šæ•°GPUçš„çƒ­èŠ‚æµæ¸©åº¦
            return 83.0
        except:
            return 83.0
    
    def _measure_p2p_bandwidth(self, gpu_a: int, gpu_b: int) -> float:
        """æµ‹é‡P2På¸¦å®½"""
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            test_size = 128 * 1024 * 1024  # 128MB
            test_data = torch.randn(test_size // 4, dtype=torch.float32, device=f'cuda:{gpu_a}')
            
            # é¢„çƒ­
            for _ in range(3):
                _ = test_data.to(f'cuda:{gpu_b}')
                torch.cuda.synchronize()
            
            # æµ‹é‡ä¼ è¾“æ—¶é—´
            torch.cuda.synchronize()
            start_time = time.time()
            
            for _ in range(10):
                transferred = test_data.to(f'cuda:{gpu_b}')
                torch.cuda.synchronize()
            
            end_time = time.time()
            
            # è®¡ç®—å¸¦å®½
            total_bytes = test_size * 10
            total_time = end_time - start_time
            bandwidth_gbps = (total_bytes / total_time) / (1024**3)
            
            return bandwidth_gbps
            
        except Exception as e:
            logger.warning(f"æµ‹é‡P2På¸¦å®½å¤±è´¥: {e}")
            return 16.0  # é»˜è®¤PCIe 3.0 x16å¸¦å®½
    
    def _log_topology_summary(self):
        """è®°å½•æ‹“æ‰‘æ‘˜è¦"""
        if not self.device_topology:
            return
        
        logger.info("=== è®¾å¤‡æ‹“æ‰‘æ‘˜è¦ ===")
        
        # è®¾å¤‡æ‘˜è¦
        device_counts = defaultdict(int)
        for device in self.device_topology.devices.values():
            device_counts[device.device_type.value] += 1
        
        for device_type, count in device_counts.items():
            logger.info(f"{device_type.upper()}: {count}ä¸ªè®¾å¤‡")
        
        # äº’è”æ‘˜è¦
        interconnect_counts = defaultdict(int)
        for interconnect in self.device_topology.interconnects:
            interconnect_counts[interconnect.interconnect_type.value] += 1
        
        for interconnect_type, count in interconnect_counts.items():
            logger.info(f"{interconnect_type.upper()}äº’è”: {count}ä¸ª")
    
    def get_optimal_device_allocation(self, workload_size: int, 
                                    memory_requirement: int) -> Dict[str, float]:
        """è·å–æœ€ä¼˜è®¾å¤‡åˆ†é…"""
        if not self.device_topology:
            return {}
        
        allocation = {}
        
        # è®¡ç®—æ¯ä¸ªè®¾å¤‡çš„é€‚åˆåº¦åˆ†æ•°
        device_scores = {}
        for device_id, capability in self.device_topology.devices.items():
            if capability.device_type != DeviceType.GPU:
                continue
            
            # ç»¼åˆè¯„åˆ†ï¼šè®¡ç®—èƒ½åŠ› + å†…å­˜å®¹é‡ + å¯ç”¨æ€§
            compute_score = capability.compute_capability
            memory_score = min(capability.memory_total / memory_requirement, 1.0)
            utilization_score = 1.0 - self._get_current_utilization(device_id)
            
            total_score = compute_score * 0.4 + memory_score * 0.4 + utilization_score * 0.2
            device_scores[device_id] = total_score
        
        # æŒ‰åˆ†æ•°æ’åºå¹¶åˆ†é…
        sorted_devices = sorted(device_scores.items(), key=lambda x: x[1], reverse=True)
        
        remaining_workload = 1.0
        for device_id, score in sorted_devices:
            if remaining_workload <= 0:
                break
            
            # æ ¹æ®è®¾å¤‡èƒ½åŠ›åˆ†é…å·¥ä½œè´Ÿè½½æ¯”ä¾‹
            allocation_ratio = min(score, remaining_workload)
            allocation[device_id] = allocation_ratio
            remaining_workload -= allocation_ratio
        
        return allocation
    
    def _get_current_utilization(self, device_id: str) -> float:
        """è·å–å½“å‰è®¾å¤‡åˆ©ç”¨ç‡"""
        if device_id.startswith('cuda:'):
            try:
                gpu_id = int(device_id.split(':')[1])
                return torch.cuda.utilization(gpu_id) / 100.0
            except:
                return 0.0
        return 0.0
    
    def get_transfer_strategy(self, src_device: str, dst_device: str, 
                            data_size: int) -> Dict[str, Any]:
        """è·å–æ•°æ®ä¼ è¾“ç­–ç•¥"""
        if not self.device_topology:
            return {"strategy": "direct"}
        
        bandwidth = self.device_topology.get_bandwidth(src_device, dst_device)
        
        if bandwidth > 50.0:  # é«˜å¸¦å®½è¿æ¥
            return {
                "strategy": "direct_p2p",
                "chunk_size": min(data_size, 256 * 1024 * 1024),  # 256MB chunks
                "async": True
            }
        elif bandwidth > 0:  # ä¸­ç­‰å¸¦å®½
            return {
                "strategy": "direct",
                "chunk_size": min(data_size, 64 * 1024 * 1024),   # 64MB chunks
                "async": False
            }
        else:  # æ— ç›´è¿ï¼Œé€šè¿‡ç³»ç»Ÿå†…å­˜
            return {
                "strategy": "via_system_memory",
                "chunk_size": min(data_size, 32 * 1024 * 1024),   # 32MB chunks
                "async": False
            }
    
    def get_device_topology(self) -> Optional[DeviceTopology]:
        """è·å–è®¾å¤‡æ‹“æ‰‘"""
        return self.device_topology
    
    def get_device_recommendations(self) -> Dict[str, Any]:
        """è·å–è®¾å¤‡ä½¿ç”¨å»ºè®®"""
        if not self.device_topology:
            return {}
        
        recommendations = {
            "optimal_strategies": {},
            "bottlenecks": [],
            "optimizations": []
        }
        
        gpu_devices = [d for d in self.device_topology.devices.values() 
                      if d.device_type == DeviceType.GPU]
        
        if len(gpu_devices) == 1:
            recommendations["optimal_strategies"]["inference"] = "single_gpu_optimized"
            recommendations["optimizations"].append("å¯ç”¨æ··åˆç²¾åº¦æ¨ç†")
            recommendations["optimizations"].append("æ¿€æ´»å†…å­˜æ± åŒ–")
        
        elif len(gpu_devices) == 2:
            recommendations["optimal_strategies"]["inference"] = "dual_gpu_pipeline"
            recommendations["optimizations"].append("å¯ç”¨GPUé—´æµæ°´çº¿")
            recommendations["optimizations"].append("ä½¿ç”¨P2Pä¼ è¾“ä¼˜åŒ–")
        
        elif len(gpu_devices) > 2:
            recommendations["optimal_strategies"]["inference"] = "multi_gpu_distributed"
            recommendations["optimizations"].append("å¯ç”¨æ¨¡å‹å¹¶è¡Œ")
            recommendations["optimizations"].append("ä½¿ç”¨é›†åˆé€šä¿¡ä¼˜åŒ–")
        
        return recommendations
    
    def start_monitoring(self):
        """å¯åŠ¨æ€§èƒ½ç›‘æ§"""
        if self.monitoring_enabled:
            return
        
        self.monitoring_enabled = True
        self.monitoring_thread = threading.Thread(target=self._monitoring_loop)
        self.monitoring_thread.daemon = True
        self.monitoring_thread.start()
        logger.info("è®¾å¤‡æ€§èƒ½ç›‘æ§å·²å¯åŠ¨")
    
    def stop_monitoring(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        self.monitoring_enabled = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=2.0)
        logger.info("è®¾å¤‡æ€§èƒ½ç›‘æ§å·²åœæ­¢")
    
    def _monitoring_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring_enabled:
            try:
                with self._monitor_lock:
                    self._update_performance_metrics()
                time.sleep(5.0)  # æ¯5ç§’æ›´æ–°ä¸€æ¬¡
            except Exception as e:
                logger.error(f"ç›‘æ§å¾ªç¯é”™è¯¯: {e}")
                time.sleep(10.0)
    
    def _update_performance_metrics(self):
        """æ›´æ–°æ€§èƒ½æŒ‡æ ‡"""
        if not self.device_topology:
            return
        
        for device_id, capability in self.device_topology.devices.items():
            if capability.device_type == DeviceType.GPU:
                utilization = self._get_current_utilization(device_id)
                self.performance_history[device_id].append(utilization)
                
                # ä¿æŒå†å²é•¿åº¦
                if len(self.performance_history[device_id]) > 100:
                    self.performance_history[device_id] = self.performance_history[device_id][-50:] 