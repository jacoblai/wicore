"""
WiCoreè®¾å¤‡ç®¡ç†å™¨  
åŸºäºå·²éªŒè¯çš„ç¡¬ä»¶æ£€æµ‹é€»è¾‘ï¼Œæ”¯æŒå¼‚æ„ç¡¬ä»¶ç»Ÿä¸€æŠ½è±¡

æ ¸å¿ƒåŠŸèƒ½:
- å®æ—¶ç¡¬ä»¶å‘ç°å’ŒçŠ¶æ€ç›‘æ§
- å¼‚æ„è®¾å¤‡ç»Ÿä¸€æŠ½è±¡ï¼ˆGPUã€CPUã€NPUç­‰ï¼‰
- è®¾å¤‡æ‹“æ‰‘åˆ†æå’Œä¼˜åŒ–å»ºè®®
- å†…å­˜å’Œè®¡ç®—èµ„æºç®¡ç†
- è®¾å¤‡å¥åº·çŠ¶æ€ç›‘æ§
"""

import torch
import logging
import subprocess
import time
import threading
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from enum import Enum
import json
import psutil
import numpy as np

logger = logging.getLogger(__name__)


class DeviceType(Enum):
    """è®¾å¤‡ç±»å‹"""
    GPU = "gpu"
    CPU = "cpu" 
    NPU = "npu"
    TPU = "tpu"
    FPGA = "fpga"


@dataclass  
class DeviceInfo:
    """è®¾å¤‡ä¿¡æ¯"""
    device_id: str
    device_type: DeviceType
    name: str
    memory_total: int           # æ€»å†…å­˜ï¼ˆå­—èŠ‚ï¼‰
    memory_available: int       # å¯ç”¨å†…å­˜ï¼ˆå­—èŠ‚ï¼‰
    compute_capability: float   # è®¡ç®—èƒ½åŠ›è¯„åˆ†
    numa_node: int             # NUMAèŠ‚ç‚¹
    pcie_bandwidth: float      # PCIeå¸¦å®½ï¼ˆGB/sï¼‰
    power_usage: float         # åŠŸè€—ï¼ˆç“¦ç‰¹ï¼‰
    temperature: float         # æ¸©åº¦ï¼ˆæ‘„æ°åº¦ï¼‰
    utilization: float         # åˆ©ç”¨ç‡ï¼ˆ0-1ï¼‰
    is_available: bool         # æ˜¯å¦å¯ç”¨
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        result = asdict(self)
        result['device_type'] = self.device_type.value
        return result
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'DeviceInfo':
        """ä»å­—å…¸åˆ›å»º"""
        data['device_type'] = DeviceType(data['device_type'])
        return cls(**data)


@dataclass
class DeviceTopology:
    """è®¾å¤‡æ‹“æ‰‘ä¿¡æ¯"""
    device_connections: Dict[str, List[str]]         # è®¾å¤‡è¿æ¥å…³ç³»
    bandwidth_matrix: Dict[str, Dict[str, float]]   # å¸¦å®½çŸ©é˜µ
    numa_topology: Dict[int, List[str]]             # NUMAæ‹“æ‰‘
    optimal_placement: Dict[str, str]               # æœ€ä¼˜æ”¾ç½®å»ºè®®


class DeviceManager:
    """è®¾å¤‡ç®¡ç†å™¨"""
    
    def __init__(self):
        self.devices: Dict[str, DeviceInfo] = {}
        self.topology: Optional[DeviceTopology] = None
        self.monitoring_active = False
        self.monitor_thread: Optional[threading.Thread] = None
        self.monitor_interval = 5.0  # 5ç§’ç›‘æ§é—´éš”
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.discovery_time = 0
        self.total_compute_power = 0.0
        self.total_memory = 0
        self.available_memory = 0
        
        # æ‰§è¡Œåˆå§‹ç¡¬ä»¶å‘ç°
        self._discover_devices()
        self._analyze_topology()
        
        logger.info(f"è®¾å¤‡ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ: å‘ç°{len(self.devices)}ä¸ªè®¾å¤‡")
    
    def _discover_devices(self):
        """å‘ç°ç¡¬ä»¶è®¾å¤‡"""
        start_time = time.time()
        logger.info("ğŸ” å¼€å§‹è®¾å¤‡å‘ç°...")
        
        try:
            # å‘ç°GPUè®¾å¤‡
            self._discover_gpu_devices()
            
            # å‘ç°CPUè®¾å¤‡  
            self._discover_cpu_devices()
            
            # å‘ç°å…¶ä»–è®¾å¤‡ï¼ˆNPUã€TPUç­‰ï¼‰
            self._discover_other_devices()
            
            self.discovery_time = time.time() - start_time
            
            # è®¡ç®—æ€»ä½“ç»Ÿè®¡
            self._calculate_system_stats()
            
            logger.info(f"âœ… è®¾å¤‡å‘ç°å®Œæˆ: {len(self.devices)}ä¸ªè®¾å¤‡, ç”¨æ—¶{self.discovery_time:.2f}s")
            
        except Exception as e:
            logger.error(f"âŒ è®¾å¤‡å‘ç°å¤±è´¥: {e}")
    
    def _discover_gpu_devices(self):
        """å‘ç°GPUè®¾å¤‡"""
        logger.info("ğŸ“Š æ£€æµ‹GPUè®¾å¤‡...")
        
        # æ£€æµ‹NVIDIA GPU
        try:
            result = subprocess.run(
                ["nvidia-smi", "--query-gpu=index,name,memory.total,memory.free,compute_cap,temperature.gpu,power.draw,utilization.gpu", 
                 "--format=csv,noheader,nounits"],
                capture_output=True, text=True, check=True
            )
            
            gpu_output = result.stdout.strip()
            if gpu_output:
                gpu_lines = gpu_output.split('\n')
                logger.info(f"âœ… å‘ç° {len(gpu_lines)} ä¸ªNVIDIA GPU:")
                
                for line in gpu_lines:
                    if line.strip():
                        parts = [p.strip() for p in line.split(',')]
                        if len(parts) >= 8:
                            gpu_id = f"gpu_{parts[0]}"
                            name = parts[1]
                            memory_total = int(parts[2]) * 1024 * 1024  # MB to bytes
                            memory_free = int(parts[3]) * 1024 * 1024   # MB to bytes
                            compute_cap = float(parts[4])
                            temperature = float(parts[5]) if parts[5] != 'N/A' else 0.0
                            power_usage = float(parts[6]) if parts[6] != 'N/A' else 0.0
                            utilization = float(parts[7]) / 100.0 if parts[7] != 'N/A' else 0.0
                            
                            device_info = DeviceInfo(
                                device_id=gpu_id,
                                device_type=DeviceType.GPU,
                                name=name,
                                memory_total=memory_total,
                                memory_available=memory_free,
                                compute_capability=compute_cap,
                                numa_node=0,  # éœ€è¦è¿›ä¸€æ­¥æ£€æµ‹
                                pcie_bandwidth=16.0,  # é»˜è®¤PCIe 4.0 x16
                                power_usage=power_usage,
                                temperature=temperature,
                                utilization=utilization,
                                is_available=True
                            )
                            
                            self.devices[gpu_id] = device_info
                            
                            logger.info(f"    GPU {parts[0]}: {name}")
                            logger.info(f"      å†…å­˜: {memory_free//1024//1024}MB / {memory_total//1024//1024}MB")
                            logger.info(f"      è®¡ç®—èƒ½åŠ›: {compute_cap}, æ¸©åº¦: {temperature}Â°C")
                            logger.info(f"      åŠŸè€—: {power_usage}W, åˆ©ç”¨ç‡: {utilization*100:.1f}%")
        
        except subprocess.CalledProcessError:
            logger.info("âš ï¸  nvidia-smiå‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œå¯èƒ½æ²¡æœ‰NVIDIA GPU")
        except Exception as e:
            logger.warning(f"âš ï¸  GPUæ£€æµ‹å¼‚å¸¸: {e}")
        
        # æ£€æµ‹AMD GPUï¼ˆå¦‚æœéœ€è¦ï¼‰
        # æ£€æµ‹Intel GPUï¼ˆå¦‚æœéœ€è¦ï¼‰
    
    def _discover_cpu_devices(self):
        """å‘ç°CPUè®¾å¤‡"""
        logger.info("ğŸ–¥ï¸ æ£€æµ‹CPUè®¾å¤‡...")
        
        try:
            # è·å–CPUä¿¡æ¯
            cpu_info = {}
            with open('/proc/cpuinfo', 'r') as f:
                for line in f:
                    if ':' in line:
                        key, value = line.split(':', 1)
                        key = key.strip()
                        value = value.strip()
                        if key == 'model name' and 'model_name' not in cpu_info:
                            cpu_info['model_name'] = value
                        elif key == 'cpu cores' and 'cores' not in cpu_info:
                            cpu_info['cores'] = int(value)
                        elif key == 'cpu MHz' and 'frequency' not in cpu_info:
                            cpu_info['frequency'] = float(value)
            
            # è·å–å†…å­˜ä¿¡æ¯
            memory_info = psutil.virtual_memory()
            
            # åˆ›å»ºCPUè®¾å¤‡ä¿¡æ¯
            device_info = DeviceInfo(
                device_id="cpu_0",
                device_type=DeviceType.CPU,
                name=cpu_info.get('model_name', 'Unknown CPU'),
                memory_total=memory_info.total,
                memory_available=memory_info.available,
                compute_capability=cpu_info.get('cores', 1) * cpu_info.get('frequency', 2000) / 1000,
                numa_node=0,
                pcie_bandwidth=0.0,
                power_usage=0.0,  # CPUåŠŸè€—éœ€è¦ç‰¹æ®Šæ£€æµ‹
                temperature=0.0,  # CPUæ¸©åº¦éœ€è¦ç‰¹æ®Šæ£€æµ‹
                utilization=psutil.cpu_percent() / 100.0,
                is_available=True
            )
            
            self.devices["cpu_0"] = device_info
            
            logger.info(f"âœ… CPU: {device_info.name}")
            logger.info(f"    å†…å­˜: {memory_info.available//1024//1024//1024}GB / {memory_info.total//1024//1024//1024}GB")
            logger.info(f"    æ ¸å¿ƒæ•°: {cpu_info.get('cores', 'Unknown')}")
            logger.info(f"    é¢‘ç‡: {cpu_info.get('frequency', 'Unknown')}MHz")
            
        except Exception as e:
            logger.warning(f"âš ï¸  CPUä¿¡æ¯æ£€æµ‹å¤±è´¥: {e}")
    
    def _discover_other_devices(self):
        """å‘ç°å…¶ä»–è®¾å¤‡ï¼ˆNPUã€TPUç­‰ï¼‰"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ å¯¹å…¶ä»–è®¾å¤‡çš„æ£€æµ‹é€»è¾‘
        # ä¾‹å¦‚ï¼šIntel Neural Compute Stickã€Google TPUã€åä¸ºæ˜‡è…¾NPUç­‰
        pass
    
    def _analyze_topology(self):
        """åˆ†æè®¾å¤‡æ‹“æ‰‘"""
        logger.info("ğŸ”— åˆ†æè®¾å¤‡æ‹“æ‰‘...")
        
        try:
            # è·å–GPUæ‹“æ‰‘ä¿¡æ¯
            gpu_topology = self._get_gpu_topology()
            
            # æ„å»ºæ‹“æ‰‘ç»“æ„
            device_connections = {}
            bandwidth_matrix = {}
            numa_topology = {0: list(self.devices.keys())}  # ç®€åŒ–çš„NUMAæ‹“æ‰‘
            optimal_placement = {}
            
            # åˆ†æGPUè¿æ¥
            if gpu_topology:
                for connection in gpu_topology:
                    gpu_a = f"gpu_{connection['gpu_a']}"
                    gpu_b = f"gpu_{connection['gpu_b']}"
                    link_type = connection['link_type']
                    
                    # æ·»åŠ è¿æ¥å…³ç³»
                    if gpu_a not in device_connections:
                        device_connections[gpu_a] = []
                    if gpu_b not in device_connections:
                        device_connections[gpu_b] = []
                    
                    device_connections[gpu_a].append(gpu_b)
                    device_connections[gpu_b].append(gpu_a)
                    
                    # ä¼°ç®—å¸¦å®½
                    bandwidth = self._estimate_bandwidth(link_type)
                    
                    if gpu_a not in bandwidth_matrix:
                        bandwidth_matrix[gpu_a] = {}
                    if gpu_b not in bandwidth_matrix:
                        bandwidth_matrix[gpu_b] = {}
                    
                    bandwidth_matrix[gpu_a][gpu_b] = bandwidth
                    bandwidth_matrix[gpu_b][gpu_a] = bandwidth
                    
                    logger.info(f"    {gpu_a} <-> {gpu_b}: {link_type} ({bandwidth:.1f} GB/s)")
            
            self.topology = DeviceTopology(
                device_connections=device_connections,
                bandwidth_matrix=bandwidth_matrix,
                numa_topology=numa_topology,
                optimal_placement=optimal_placement
            )
            
        except Exception as e:
            logger.warning(f"âš ï¸  æ‹“æ‰‘åˆ†æå¤±è´¥: {e}")
    
    def _get_gpu_topology(self) -> List[Dict[str, Any]]:
        """è·å–GPUæ‹“æ‰‘ä¿¡æ¯"""
        try:
            result = subprocess.run(
                ["nvidia-smi", "topo", "-m"],
                capture_output=True, text=True, check=True
            )
            
            # è§£ænvidia-smi topoè¾“å‡º
            lines = result.stdout.strip().split('\n')
            topology = []
            
            for line in lines:
                if 'GPU' in line and 'PHB' in line:
                    # ç®€åŒ–çš„è§£æï¼Œå®é™…åº”è¯¥æ›´å¤æ‚
                    parts = line.split()
                    if len(parts) >= 3:
                        gpu_a = 0  # æå–GPUç´¢å¼•
                        gpu_b = 1  # æå–GPUç´¢å¼•
                        link_type = "PHB"  # PCIe + Host Bridge
                        
                        topology.append({
                            'gpu_a': gpu_a,
                            'gpu_b': gpu_b,
                            'link_type': link_type
                        })
            
            return topology
            
        except subprocess.CalledProcessError:
            logger.info("âš ï¸  æ— æ³•è·å–GPUæ‹“æ‰‘ä¿¡æ¯")
            return []
    
    def _estimate_bandwidth(self, link_type: str) -> float:
        """ä¼°ç®—å¸¦å®½"""
        bandwidth_map = {
            'NV1': 25.0,  # NVLink 1.0
            'NV2': 50.0,  # NVLink 2.0  
            'NV3': 112.0, # NVLink 3.0
            'NV4': 112.0, # NVLink 4.0
            'PHB': 16.0,  # PCIe Host Bridge
            'PIX': 16.0,  # PCIe
            'SYS': 10.0,  # System connection
        }
        return bandwidth_map.get(link_type, 10.0)
    
    def _calculate_system_stats(self):
        """è®¡ç®—ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        self.total_compute_power = sum(
            device.compute_capability for device in self.devices.values()
        )
        self.total_memory = sum(
            device.memory_total for device in self.devices.values()
        )
        self.available_memory = sum(
            device.memory_available for device in self.devices.values()
        )
    
    def start_monitoring(self):
        """å¼€å§‹è®¾å¤‡ç›‘æ§"""
        if self.monitoring_active:
            return
        
        self.monitoring_active = True
        self.monitor_thread = threading.Thread(target=self._monitor_devices, daemon=True)
        self.monitor_thread.start()
        
        logger.info("ğŸ”„ è®¾å¤‡ç›‘æ§å·²å¯åŠ¨")
    
    def stop_monitoring(self):
        """åœæ­¢è®¾å¤‡ç›‘æ§"""
        self.monitoring_active = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=1.0)
        
        logger.info("â¹ï¸ è®¾å¤‡ç›‘æ§å·²åœæ­¢")
    
    def _monitor_devices(self):
        """ç›‘æ§è®¾å¤‡çŠ¶æ€"""
        while self.monitoring_active:
            try:
                # æ›´æ–°GPUçŠ¶æ€
                self._update_gpu_status()
                
                # æ›´æ–°CPUçŠ¶æ€
                self._update_cpu_status()
                
                # é‡æ–°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                self._calculate_system_stats()
                
                time.sleep(self.monitor_interval)
                
            except Exception as e:
                logger.warning(f"è®¾å¤‡ç›‘æ§å¼‚å¸¸: {e}")
                time.sleep(self.monitor_interval)
    
    def _update_gpu_status(self):
        """æ›´æ–°GPUçŠ¶æ€"""
        try:
            result = subprocess.run(
                ["nvidia-smi", "--query-gpu=index,memory.free,temperature.gpu,power.draw,utilization.gpu",
                 "--format=csv,noheader,nounits"],
                capture_output=True, text=True, check=True
            )
            
            for line in result.stdout.strip().split('\n'):
                if line.strip():
                    parts = [p.strip() for p in line.split(',')]
                    if len(parts) >= 5:
                        gpu_id = f"gpu_{parts[0]}"
                        if gpu_id in self.devices:
                            device = self.devices[gpu_id]
                            device.memory_available = int(parts[1]) * 1024 * 1024
                            device.temperature = float(parts[2]) if parts[2] != 'N/A' else 0.0
                            device.power_usage = float(parts[3]) if parts[3] != 'N/A' else 0.0
                            device.utilization = float(parts[4]) / 100.0 if parts[4] != 'N/A' else 0.0
                            
        except subprocess.CalledProcessError:
            pass
    
    def _update_cpu_status(self):
        """æ›´æ–°CPUçŠ¶æ€"""
        try:
            if "cpu_0" in self.devices:
                memory_info = psutil.virtual_memory()
                cpu_percent = psutil.cpu_percent()
                
                device = self.devices["cpu_0"]
                device.memory_available = memory_info.available
                device.utilization = cpu_percent / 100.0
                
        except Exception:
            pass
    
    def get_device(self, device_id: str) -> Optional[DeviceInfo]:
        """è·å–è®¾å¤‡ä¿¡æ¯"""
        return self.devices.get(device_id)
    
    def get_devices_by_type(self, device_type: DeviceType) -> List[DeviceInfo]:
        """æŒ‰ç±»å‹è·å–è®¾å¤‡"""
        return [device for device in self.devices.values() if device.device_type == device_type]
    
    def get_available_devices(self) -> List[DeviceInfo]:
        """è·å–å¯ç”¨è®¾å¤‡"""
        return [device for device in self.devices.values() if device.is_available]
    
    def get_optimal_device(self, memory_required: int = 0) -> Optional[DeviceInfo]:
        """è·å–æœ€ä¼˜è®¾å¤‡"""
        available_devices = self.get_available_devices()
        
        # æŒ‰è®¡ç®—èƒ½åŠ›å’Œå¯ç”¨å†…å­˜æ’åº
        scored_devices = []
        for device in available_devices:
            if device.memory_available >= memory_required:
                score = device.compute_capability * (1 - device.utilization)
                scored_devices.append((score, device))
        
        if scored_devices:
            scored_devices.sort(reverse=True)
            return scored_devices[0][1]
        
        return None
    
    def get_system_stats(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        gpu_devices = self.get_devices_by_type(DeviceType.GPU)
        cpu_devices = self.get_devices_by_type(DeviceType.CPU)
        
        return {
            "total_devices": len(self.devices),
            "gpu_count": len(gpu_devices),
            "cpu_count": len(cpu_devices),
            "total_compute_power": self.total_compute_power,
            "total_memory_gb": self.total_memory / 1024 / 1024 / 1024,
            "available_memory_gb": self.available_memory / 1024 / 1024 / 1024,
            "memory_utilization": 1 - (self.available_memory / max(self.total_memory, 1)),
            "discovery_time": self.discovery_time,
            "monitoring_active": self.monitoring_active,
            "devices": [device.to_dict() for device in self.devices.values()]
        }
    
    def export_config(self, filepath: str):
        """å¯¼å‡ºè®¾å¤‡é…ç½®"""
        config = {
            "devices": {device_id: device.to_dict() for device_id, device in self.devices.items()},
            "topology": {
                "device_connections": self.topology.device_connections if self.topology else {},
                "bandwidth_matrix": self.topology.bandwidth_matrix if self.topology else {},
                "numa_topology": self.topology.numa_topology if self.topology else {},
                "optimal_placement": self.topology.optimal_placement if self.topology else {}
            } if self.topology else {},
            "system_stats": self.get_system_stats()
        }
        
        with open(filepath, 'w') as f:
            json.dump(config, f, indent=2)
        
        logger.info(f"è®¾å¤‡é…ç½®å·²å¯¼å‡º: {filepath}")
    
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        self.stop_monitoring() 