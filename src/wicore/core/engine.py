"""
WiCoreä¸»å¼•æ“Ž
åè°ƒæ‰€æœ‰å­ç³»ç»Ÿè¿ä½œçš„æ ¸å¿ƒæŽ§åˆ¶å™¨

æ ¸å¿ƒèŒè´£:
- ç³»ç»Ÿåˆå§‹åŒ–å’Œç”Ÿå‘½å‘¨æœŸç®¡ç†
- å„å­ç³»ç»Ÿåè°ƒå’Œé€šä¿¡
- èµ„æºåˆ†é…å’Œè°ƒåº¦
- æ€§èƒ½ç›‘æŽ§å’Œä¼˜åŒ–
- æ•…éšœæ£€æµ‹å’Œæ¢å¤
"""

import torch
import logging
import asyncio
import threading
import time
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass
from enum import Enum
import signal
import sys

from .config import WiCoreConfig, get_config_manager
from .device_manager import DeviceManager
from .inference_engine import InferenceEngine
from ..memory.hmt_manager import HMTManager
from ..routing.mor_router import MoRRouter
from ..memory.kv_cache import get_kv_cache_manager

logger = logging.getLogger(__name__)


class EngineState(Enum):
    """å¼•æ“ŽçŠ¶æ€"""
    UNINITIALIZED = "uninitialized"
    INITIALIZING = "initializing"
    READY = "ready"
    RUNNING = "running"
    STOPPING = "stopping"
    STOPPED = "stopped"
    ERROR = "error"


@dataclass
class EngineStats:
    """å¼•æ“Žç»Ÿè®¡ä¿¡æ¯"""
    start_time: float
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    average_latency: float = 0.0
    peak_memory_usage: int = 0
    total_tokens_processed: int = 0
    current_qps: float = 0.0


class WiCoreEngine:
    """WiCoreä¸»å¼•æ“Ž"""
    
    def __init__(self, config: Optional[WiCoreConfig] = None):
        self.config = config or WiCoreConfig()
        self.state = EngineState.UNINITIALIZED
        
        # æ ¸å¿ƒç»„ä»¶
        self.device_manager: Optional[DeviceManager] = None
        self.inference_engine: Optional[InferenceEngine] = None
        self.hmt_manager: Optional[HMTManager] = None
        self.mor_router: Optional[MoRRouter] = None
        self.kv_cache_manager = None
        
        # è¿è¡Œæ—¶çŠ¶æ€
        self.stats = EngineStats(start_time=time.time())
        self.is_shutdown = False
        self.background_tasks: List[asyncio.Task] = []
        
        # é”å’Œäº‹ä»¶
        self.state_lock = threading.RLock()
        self.shutdown_event = threading.Event()
        
        # ç›‘æŽ§çº¿ç¨‹
        self.monitor_thread: Optional[threading.Thread] = None
        
        logger.info("WiCoreå¼•æ“Žå®žä¾‹å·²åˆ›å»º")
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–å¼•æ“Ž"""
        with self.state_lock:
            if self.state != EngineState.UNINITIALIZED:
                logger.warning(f"å¼•æ“ŽçŠ¶æ€é”™è¯¯ï¼Œæ— æ³•åˆå§‹åŒ–: {self.state}")
                return False
            
            self.state = EngineState.INITIALIZING
        
        try:
            logger.info("ðŸš€ å¼€å§‹åˆå§‹åŒ–WiCoreå¼•æ“Ž...")
            
            # åˆå§‹åŒ–è®¾å¤‡ç®¡ç†å™¨
            await self._initialize_device_manager()
            
            # åˆå§‹åŒ–æŽ¨ç†å¼•æ“Žï¼ˆåŒ…å«æ¨¡åž‹åŠ è½½ã€HMTã€MoRç­‰ï¼‰
            await self._initialize_inference_engine()
            
            # åˆå§‹åŒ–KVç¼“å­˜ç®¡ç†
            await self._initialize_kv_cache()
            
            # å¯åŠ¨ç›‘æŽ§ç³»ç»Ÿ
            await self._start_monitoring()
            
            # æ³¨å†Œä¿¡å·å¤„ç†
            self._register_signal_handlers()
            
            with self.state_lock:
                self.state = EngineState.READY
            
            logger.info("âœ… WiCoreå¼•æ“Žåˆå§‹åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¼•æ“Žåˆå§‹åŒ–å¤±è´¥: {e}")
            with self.state_lock:
                self.state = EngineState.ERROR
            return False
    
    async def _initialize_device_manager(self):
        """åˆå§‹åŒ–è®¾å¤‡ç®¡ç†å™¨"""
        logger.info("ðŸ“± åˆå§‹åŒ–è®¾å¤‡ç®¡ç†å™¨...")
        
        self.device_manager = DeviceManager()
        
        # å¯åŠ¨è®¾å¤‡ç›‘æŽ§
        if self.config.performance.enable_gpu_monitoring:
            self.device_manager.start_monitoring()
        
        # èŽ·å–ç³»ç»Ÿç»Ÿè®¡
        stats = self.device_manager.get_system_stats()
        logger.info(f"è®¾å¤‡å‘çŽ°å®Œæˆ: {stats['gpu_count']}ä¸ªGPU, {stats['total_memory_gb']:.1f}GBæ€»å†…å­˜")
    
    async def _initialize_inference_engine(self):
        """åˆå§‹åŒ–æŽ¨ç†å¼•æ“Žï¼ˆæ•´åˆæ‰€æœ‰ç»„ä»¶ï¼‰"""
        logger.info("ðŸš€ åˆå§‹åŒ–æŽ¨ç†å¼•æ“Ž...")
        
        # åˆ›å»ºæŽ¨ç†å¼•æ“Žï¼Œå®ƒä¼šè‡ªåŠ¨åˆå§‹åŒ–HMTã€MoRç­‰ç»„ä»¶
        self.inference_engine = InferenceEngine(self.config)
        
        # åˆå§‹åŒ–æŽ¨ç†å¼•æ“Ž
        success = await self.inference_engine.initialize()
        if not success:
            raise RuntimeError("æŽ¨ç†å¼•æ“Žåˆå§‹åŒ–å¤±è´¥")
        
        # ä»ŽæŽ¨ç†å¼•æ“ŽèŽ·å–å­ç»„ä»¶å¼•ç”¨
        self.hmt_manager = self.inference_engine.hmt_manager
        self.mor_router = self.inference_engine.mor_router
        
        logger.info("æŽ¨ç†å¼•æ“Žåˆå§‹åŒ–å®Œæˆ")
    
    async def _initialize_kv_cache(self):
        """åˆå§‹åŒ–KVç¼“å­˜ç®¡ç†"""
        if not self.config.attention.enable_kv_cache:
            logger.info("â­ï¸ KVç¼“å­˜å·²ç¦ç”¨")
            return
        
        logger.info("ðŸ’¾ åˆå§‹åŒ–KVç¼“å­˜ç®¡ç†å™¨...")
        
        # èŽ·å–å…¨å±€KVç¼“å­˜ç®¡ç†å™¨
        self.kv_cache_manager = get_kv_cache_manager()
        
        logger.info("KVç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def _start_monitoring(self):
        """å¯åŠ¨ç›‘æŽ§ç³»ç»Ÿ"""
        if not self.config.performance.enable_monitoring:
            logger.info("â­ï¸ æ€§èƒ½ç›‘æŽ§å·²ç¦ç”¨")
            return
        
        logger.info("ðŸ“Š å¯åŠ¨æ€§èƒ½ç›‘æŽ§...")
        
        # å¯åŠ¨ç›‘æŽ§çº¿ç¨‹
        self.monitor_thread = threading.Thread(
            target=self._monitor_performance,
            daemon=True
        )
        self.monitor_thread.start()
        
        logger.info("æ€§èƒ½ç›‘æŽ§å·²å¯åŠ¨")
    
    def _register_signal_handlers(self):
        """æ³¨å†Œä¿¡å·å¤„ç†å™¨"""
        def signal_handler(signum, frame):
            logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
            asyncio.create_task(self.shutdown())
        
        # åªåœ¨ä¸»çº¿ç¨‹ä¸­æ³¨å†Œä¿¡å·å¤„ç†å™¨
        if threading.current_thread() is threading.main_thread():
            signal.signal(signal.SIGINT, signal_handler)
            signal.signal(signal.SIGTERM, signal_handler)
    
    def _monitor_performance(self):
        """æ€§èƒ½ç›‘æŽ§çº¿ç¨‹"""
        logger.info("æ€§èƒ½ç›‘æŽ§çº¿ç¨‹å·²å¯åŠ¨")
        
        while not self.shutdown_event.is_set():
            try:
                # æ”¶é›†æ€§èƒ½æŒ‡æ ‡
                self._collect_performance_metrics()
                
                # ç­‰å¾…ä¸‹æ¬¡ç›‘æŽ§
                self.shutdown_event.wait(self.config.performance.metrics_interval)
                
            except Exception as e:
                logger.error(f"æ€§èƒ½ç›‘æŽ§å¼‚å¸¸: {e}")
                time.sleep(1.0)
    
    def _collect_performance_metrics(self):
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        try:
            # ç³»ç»Ÿå†…å­˜ä½¿ç”¨
            if self.device_manager:
                stats = self.device_manager.get_system_stats()
                current_memory = stats.get('total_memory_gb', 0) - stats.get('available_memory_gb', 0)
                self.stats.peak_memory_usage = max(self.stats.peak_memory_usage, int(current_memory * 1024 * 1024 * 1024))
            
            # HMTå†…å­˜ç»Ÿè®¡
            if self.hmt_manager:
                hmt_stats = self.hmt_manager.get_memory_stats()
                logger.debug(f"HMTç»Ÿè®¡: {hmt_stats}")
            
            # KVç¼“å­˜ç»Ÿè®¡
            if self.kv_cache_manager:
                cache_stats = self.kv_cache_manager.get_cache_stats()
                logger.debug(f"KVç¼“å­˜ç»Ÿè®¡: å‘½ä¸­çŽ‡ {cache_stats['global_hit_rate']:.2%}")
            
            # è®¡ç®—QPS
            current_time = time.time()
            elapsed_time = current_time - self.stats.start_time
            if elapsed_time > 0:
                self.stats.current_qps = self.stats.total_requests / elapsed_time
            
        except Exception as e:
            logger.warning(f"æ€§èƒ½æŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")
    
    async def start(self):
        """å¯åŠ¨å¼•æ“Ž"""
        with self.state_lock:
            if self.state != EngineState.READY:
                logger.error(f"å¼•æ“ŽçŠ¶æ€é”™è¯¯ï¼Œæ— æ³•å¯åŠ¨: {self.state}")
                return False
            
            self.state = EngineState.RUNNING
        
        logger.info("ðŸŽ¯ WiCoreå¼•æ“Žå·²å¯åŠ¨")
        return True
    
    async def process_request(self, request_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æŽ¨ç†è¯·æ±‚"""
        if self.state != EngineState.RUNNING:
            raise RuntimeError(f"å¼•æ“Žæœªè¿è¡Œï¼Œå½“å‰çŠ¶æ€: {self.state}")
        
        if not self.inference_engine or not self.inference_engine.is_ready():
            raise RuntimeError("æŽ¨ç†å¼•æ“Žæœªå°±ç»ª")
        
        request_start_time = time.time()
        self.stats.total_requests += 1
        
        try:
            # ä½¿ç”¨æŽ¨ç†å¼•æ“Žå¤„ç†è¯·æ±‚
            from .inference_engine import InferenceRequest
            
            # æž„å»ºæŽ¨ç†è¯·æ±‚
            inference_request = InferenceRequest(
                request_id=request_data.get("request_id", "unknown"),
                messages=request_data.get("messages", []),
                max_tokens=request_data.get("max_tokens", 512),
                temperature=request_data.get("temperature", 0.7),
                top_p=request_data.get("top_p", 0.9),
                top_k=request_data.get("top_k", 50),
                stream=request_data.get("stream", False)
            )
            
            # æ‰§è¡ŒæŽ¨ç†
            inference_response = await self.inference_engine.generate_text(inference_request)
            
            response = {
                "status": "success",
                "request_id": inference_response.request_id,
                "response": inference_response.text,
                "finish_reason": inference_response.finish_reason,
                "tokens_generated": inference_response.tokens_generated,
                "processing_time": inference_response.processing_time,
                "model_info": inference_response.model_info
            }
            
            self.stats.successful_requests += 1
            self.stats.total_tokens_processed += inference_response.tokens_generated
            
            # æ›´æ–°å¹³å‡å»¶è¿Ÿ
            total_time = time.time() - self.stats.start_time
            if self.stats.successful_requests > 0:
                self.stats.average_latency = total_time / self.stats.successful_requests
            
            return response
            
        except Exception as e:
            self.stats.failed_requests += 1
            logger.error(f"è¯·æ±‚å¤„ç†å¤±è´¥: {e}")
            
            return {
                "status": "error",
                "request_id": request_data.get("request_id", "unknown"),
                "error": str(e),
                "processing_time": time.time() - request_start_time
            }
    
    async def shutdown(self):
        """å…³é—­å¼•æ“Ž"""
        with self.state_lock:
            if self.state in [EngineState.STOPPING, EngineState.STOPPED]:
                logger.info("å¼•æ“Žå·²åœ¨å…³é—­è¿‡ç¨‹ä¸­")
                return
            
            self.state = EngineState.STOPPING
        
        logger.info("ðŸ›‘ å¼€å§‹å…³é—­WiCoreå¼•æ“Ž...")
        
        try:
            # è®¾ç½®å…³é—­æ ‡å¿—
            self.is_shutdown = True
            self.shutdown_event.set()
            
            # å–æ¶ˆåŽå°ä»»åŠ¡
            for task in self.background_tasks:
                if not task.done():
                    task.cancel()
                    try:
                        await task
                    except asyncio.CancelledError:
                        pass
            
            # åœæ­¢ç›‘æŽ§çº¿ç¨‹
            if self.monitor_thread and self.monitor_thread.is_alive():
                self.monitor_thread.join(timeout=2.0)
            
            # å…³é—­æŽ¨ç†å¼•æ“Ž
            if self.inference_engine:
                await self.inference_engine.shutdown()
            
            # å…³é—­è®¾å¤‡ç®¡ç†å™¨
            if self.device_manager:
                self.device_manager.stop_monitoring()
            
            # æ¸…ç†å…¶ä»–èµ„æº
            # æŽ¨ç†å¼•æ“Žä¼šè‡ªåŠ¨æ¸…ç†HMTå’ŒMoRç­‰å­ç»„ä»¶
            
            with self.state_lock:
                self.state = EngineState.STOPPED
            
            logger.info("âœ… WiCoreå¼•æ“Žå·²å…³é—­")
            
        except Exception as e:
            logger.error(f"âŒ å¼•æ“Žå…³é—­å¼‚å¸¸: {e}")
            with self.state_lock:
                self.state = EngineState.ERROR
    
    def get_status(self) -> Dict[str, Any]:
        """èŽ·å–å¼•æ“ŽçŠ¶æ€"""
        return {
            "state": self.state.value,
            "uptime": time.time() - self.stats.start_time,
            "stats": {
                "total_requests": self.stats.total_requests,
                "successful_requests": self.stats.successful_requests,
                "failed_requests": self.stats.failed_requests,
                "success_rate": self.stats.successful_requests / max(self.stats.total_requests, 1),
                "average_latency": self.stats.average_latency,
                "current_qps": self.stats.current_qps,
                "peak_memory_usage_gb": self.stats.peak_memory_usage / 1024 / 1024 / 1024,
                "total_tokens_processed": self.stats.total_tokens_processed
            },
            "components": {
                "device_manager": self.device_manager is not None,
                "inference_engine": self.inference_engine is not None and self.inference_engine.is_ready(),
                "hmt_manager": self.hmt_manager is not None,
                "mor_router": self.mor_router is not None,
                "kv_cache_manager": self.kv_cache_manager is not None,
            }
        }
    
    def get_detailed_stats(self) -> Dict[str, Any]:
        """èŽ·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_status()
        
        # æ·»åŠ è®¾å¤‡ç»Ÿè®¡
        if self.device_manager:
            stats["device_stats"] = self.device_manager.get_system_stats()
        
        # æ·»åŠ HMTç»Ÿè®¡
        if self.hmt_manager:
            stats["hmt_stats"] = self.hmt_manager.get_memory_stats()
        
        # æ·»åŠ æŽ¨ç†å¼•æ“Žç»Ÿè®¡
        if self.inference_engine:
            stats["inference_stats"] = self.inference_engine.get_stats()
        
        # æ·»åŠ KVç¼“å­˜ç»Ÿè®¡
        if self.kv_cache_manager:
            stats["kv_cache_stats"] = self.kv_cache_manager.get_cache_stats()
        
        return stats
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        health_status = {
            "healthy": True,
            "timestamp": time.time(),
            "checks": {}
        }
        
        # æ£€æŸ¥å¼•æ“ŽçŠ¶æ€
        health_status["checks"]["engine_state"] = {
            "healthy": self.state == EngineState.RUNNING,
            "state": self.state.value
        }
        
        # æ£€æŸ¥è®¾å¤‡ç®¡ç†å™¨
        if self.device_manager:
            available_devices = len(self.device_manager.get_available_devices())
            health_status["checks"]["devices"] = {
                "healthy": available_devices > 0,
                "available_devices": available_devices
            }
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        if self.device_manager:
            stats = self.device_manager.get_system_stats()
            memory_usage = 1 - (stats.get('available_memory_gb', 0) / max(stats.get('total_memory_gb', 1), 1))
            health_status["checks"]["memory"] = {
                "healthy": memory_usage < 0.9,  # 90%é˜ˆå€¼
                "usage": memory_usage
            }
        
        # ç»¼åˆå¥åº·çŠ¶æ€
        health_status["healthy"] = all(
            check.get("healthy", False) for check in health_status["checks"].values()
        )
        
        return health_status
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        # åœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­ï¼Œæˆ‘ä»¬åªèƒ½è®¾ç½®å…³é—­æ ‡å¿—
        self.is_shutdown = True
        self.shutdown_event.set()
        
        # å¦‚æžœåœ¨å¼‚æ­¥çŽ¯å¢ƒä¸­ï¼Œéœ€è¦ç”¨æˆ·æ‰‹åŠ¨è°ƒç”¨ await engine.shutdown()
        if exc_type:
            logger.error(f"å¼•æ“Žä¸Šä¸‹æ–‡å¼‚å¸¸: {exc_type.__name__}: {exc_val}")
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        await self.initialize()
        await self.start()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        await self.shutdown()
        if exc_type:
            logger.error(f"å¼•æ“Žå¼‚æ­¥ä¸Šä¸‹æ–‡å¼‚å¸¸: {exc_type.__name__}: {exc_val}") 